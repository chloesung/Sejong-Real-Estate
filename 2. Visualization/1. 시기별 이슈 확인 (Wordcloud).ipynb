{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "# 2. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) 함수정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plot_grid_map 함수: QGIS를 활용하여 만든 500X500격자와 주어진 데이터를 id(그리드)별로 통합하여 FisherJenks 이론을 바탕으로 세종특별자치시 지도 위에 단계(k)별로 그리는 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mapclassify as mc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "%config InlineBackend.figure_format='retina' #화질 좋게 해주기\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "nanumr = fm.FontProperties(fname='NanumSquareOTFRegular.otf', size=18)\n",
    "nanumb = fm.FontProperties(fname='NanumSquareOTFBold.otf', size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_grid_map(df, col, k = 6, title = 'No name', mode = None, cls_dict = None, how = None,\n",
    "                  annotation = False, percen = True, colors = 'Blues', c_mode = 'NaturalBreaks'):\n",
    "    \n",
    "    # 주어진 데이터를 적절히 단계별로 나누는 코드\n",
    "    if mode == 'cont_classify':\n",
    "        dfdf = df[df[col]>0]\n",
    "        if c_mode == 'NaturalBreaks':\n",
    "            quantiles = mc.NaturalBreaks(dfdf[col].dropna(), k = k)\n",
    "        elif c_mode == 'FisherJenks':\n",
    "            quantiles = mc.FisherJenks(dfdf[col].dropna(), k = k)\n",
    "        df['cls_value'] = quantiles.find_bin(df[col]).astype('str')\n",
    "        df.loc[df[col].isnull(), 'cls_value'] = 'No Data'\n",
    "        df.loc[df[col]<0, 'cls_value'] = 'Minus'\n",
    "        cmap = plt.cm.get_cmap(colors, k)\n",
    "        cmap_list = [rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "        if len(np.where(df['cls_value'].unique() == 'Minus')[0]) != 0:\n",
    "            cmap_list.append('#F78181')\n",
    "        if len(np.where(df['cls_value'].unique() == 'No Data')[0]) != 0:\n",
    "            cmap_list.append('#bdbdbd')\n",
    "        cmap_with_grey = ListedColormap(cmap_list)\n",
    "    if mode == 'cluster':\n",
    "        k = len(df[col].unique())\n",
    "        df[col].fillna(-2, inplace=True)\n",
    "        df[col].astype('int')\n",
    "        df['cls_value'] = df[col] + 1\n",
    "        df.sort_values('cls_value')\n",
    "        df.loc[df[col]<0, 'cls_value'] = 'No Data'\n",
    "        cmap = plt.cm.get_cmap(colors, k)\n",
    "        cmap_list = [rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "        if len(np.where(df['cls_value'].unique() == 'No Data')[0]) != 0:\n",
    "            cmap_list.append('#bdbdbd')\n",
    "        cmap_with_grey = ListedColormap(cmap_list)\n",
    "    \n",
    "        \n",
    "    # plot 그리는 코드\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    df.plot(column='cls_value', edgecolor='k', cmap=cmap_with_grey,linewidth=0.05,\n",
    "             legend=True, legend_kwds=dict(loc='upper right'),ax=ax)\n",
    "    \n",
    "    # 범례이름 바꾸는 코드\n",
    "    if mode == 'cont_classify':\n",
    "        legend_labels = ax.get_legend().get_texts()\n",
    "        upper_bounds = quantiles.bins\n",
    "        bounds = []\n",
    "        for index, upper_bound in enumerate(upper_bounds):\n",
    "            if index == 0:\n",
    "                lower_bound = float(df.cls_value.min())\n",
    "            else:\n",
    "                lower_bound = float(upper_bounds[index-1])\n",
    "            \n",
    "            if percen:\n",
    "                bound = '{}% - {}%'.format(round(lower_bound, 1), round(upper_bound, 1))\n",
    "            else:\n",
    "                bound = '{} - {}'.format(round(lower_bound, 2), round(upper_bound, 2))\n",
    "            bounds.append(bound)\n",
    "    if mode == 'cluster':\n",
    "        if 'No Data' in list(df['cls_value'].unique()):\n",
    "            legend_labels = ax.get_legend().get_texts()\n",
    "            bounds = []\n",
    "            for num in list(price_merge['cls_value'].unique())[0:-1]:\n",
    "                bound = 'cluster {}'.format(round(num))\n",
    "                bounds.append(bound)     \n",
    "        else:\n",
    "            legend_labels = ax.get_legend().get_texts()\n",
    "            bounds = []\n",
    "            for num in list(price_merge['cls_value'].unique()):\n",
    "                bound = 'cluster {}'.format(num)\n",
    "                bounds.append(bound)  \n",
    "        \n",
    "    # replace the numerical legend labels\n",
    "    for bound, legend_label in zip(bounds, legend_labels):\n",
    "        legend_label.set_text(bound)\n",
    "        \n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontdict={'fontsize': '25', 'fontweight' : '3'} , fontproperties=nanumr)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 색깔 팔레트: https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 시기별 이슈 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시계열로 거래 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datetime 형태로 바꿔줍니다\n",
    "\n",
    "df3, df4, df5, df6  = data3, data4, data5, data6\n",
    "df7, df8, df9, df10  = data7, data8, data9, data10\n",
    "\n",
    "df3['계약년월'] = pd.to_datetime(df3['계약년월'], format='%Y%m')\n",
    "df4['계약년월'] = pd.to_datetime(df4['계약년월'], format='%Y%m')\n",
    "df5['계약년월'] = pd.to_datetime(df5['계약년월'], format='%Y%m')\n",
    "df6['계약년월'] = pd.to_datetime(df6['계약년월'], format='%Y%m')\n",
    "df7['계약년월'] = pd.to_datetime(df7['계약년월'], format='%Y%m')\n",
    "df8['계약년월'] = pd.to_datetime(df8['계약년월'], format='%Y%m')\n",
    "df9['계약년월'] = pd.to_datetime(df9['계약년월'], format='%Y%m')\n",
    "df10['계약년월'] = pd.to_datetime(df10['계약년월'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전월세 데이터를 전세와 월세로 구분합니다\n",
    "# 1이 전세, 2가 월세\n",
    "\n",
    "df71 = df7[df7['전월세구분'] == '전세']\n",
    "df72 = df7[df7['전월세구분'] == '월세']\n",
    "df81 = df8[df8['전월세구분'] == '전세']\n",
    "df82 = df8[df8['전월세구분'] == '월세']\n",
    "df91 = df9[df9['전월세구분'] == '전세']\n",
    "df92 = df9[df9['전월세구분'] == '월세']\n",
    "df101 = df7[df7['전월세구분'] == '전세']\n",
    "df102 = df7[df7['전월세구분'] == '월세']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 월별로 계약 건수를 세주는 함수를 만듭니다\n",
    "\n",
    "def counting(df):\n",
    "    df = df.set_index('계약년월')\n",
    "    df = df.groupby([pd.Grouper(freq='1M')]).count()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 하나의 데이터프레임으로 합쳐줍니다\n",
    "\n",
    "df = DataFrame()\n",
    "df['apt_m'] = counting(df3)['계약일']\n",
    "df['vil_m'] = counting(df4)['계약일']\n",
    "df['house_m'] = counting(df5)['계약일']\n",
    "df['op_m'] = counting(df6)['계약일']\n",
    "df['apt_j'] = counting(df71)['계약일']\n",
    "df['vil_j'] = counting(df81)['계약일']\n",
    "df['house_j'] = counting(df91)['계약일']\n",
    "df['op_j'] = counting(df101)['계약일']\n",
    "df['apt_w'] = counting(df72)['계약일']\n",
    "df['vil_w'] = counting(df82)['계약일']\n",
    "df['house_w'] = counting(df92)['계약일']\n",
    "df['op_w'] = counting(df102)['계약일']\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['apt'] = df['apt_m'] + df['apt_j'] + df['apt_w']\n",
    "df['vil'] = df['vil_m'] + df['vil_j'] + df['vil_w']\n",
    "df['house'] = df['house_m'] + df['house_j'] + df['house_w']\n",
    "df['op'] = df['op_m'] + df['op_j'] + df['op_w']\n",
    "df['buy'] = df['apt_m'] + df['vil_m'] + df['house_m'] + df['op_m']\n",
    "df['jun'] = df['apt_j'] + df['vil_j'] + df['house_j'] + df['op_j']\n",
    "df['wol'] = df['apt_w'] + df['vil_w'] + df['house_w'] + df['op_w']\n",
    "df['all'] = df['apt'] + df['vil'] + df['house'] + df['op']\n",
    "deal = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세종시 실거래량 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['all'], line = dict(color='#0B0B61', width=3)))\n",
    "fig.update_layout(title='세종시 실거래량 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세종시 거주형태별 실거래량 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['apt'], line = dict(color='#0B0B61', width=3), name='아파트'))\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['vil'], line = dict(color='#404040', width=3), name='연립다세대'))\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['house'], line = dict(color='#F3C706', width=3), name='단독다가구'))\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['op'], line = dict(color='#0B6121', width=3), name='오피스텔'))\n",
    "fig.update_layout(title='세종시 거주형태별 거래량 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세종시 거래형태별 실거래량 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['buy'], line = dict(color='#0B0B61', width=3), name='매매'))\n",
    "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['jun'], line = dict(color='#0B6121', width=3), name='전세'))\n",
    "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['wol'], line = dict(color='#F3C706', width=3), name='월세'))\n",
    "fig.update_layout(title='세종시 거래형태별 거래량 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버 뉴스 크롤링 자료 활용 (2017년 1월 ~ 2020년 12월까지, '세종시 부동산' 이라는 키워드로 뉴스 기사 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2017 = pd.read_csv('sejong2017.csv', encoding= 'utf-8')\n",
    "df2018 = pd.read_csv('sejong2018.csv', encoding= 'utf-8')\n",
    "df2019 = pd.read_csv('sejong2019.csv', encoding= 'utf-8')\n",
    "df2020 = pd.read_csv('sejong2020.csv', encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data concat\n",
    "df = pd.concat([df2017,df2018,df2019,df2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 길이 확인\n",
    "print('2017년: ',len(df2017))\n",
    "print('2018년: ',len(df2018))\n",
    "print('2019년: ',len(df2019))\n",
    "print('2020년: ',len(df2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 불용어 설정\n",
    "stopwords = ['않다','에서','있다','없다','그렇다','아니다','것','이다','의','가','이','은','들',\n",
    "             '는','좀','잘','걍','과','도','을','를','으로','자','에','와','한','하다','휴','수','세종시','세종','부동산']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터 한글과 공백을 제외하고 모두 제거\n",
    "df['title'] = df['title'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['title'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스 개수 변화 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['years'] = pd.to_datetime(df['years'], format='%Y.%m.%d.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def counting(df):\n",
    "    df = df.set_index('years')\n",
    "    df = df.groupby([pd.Grouper(freq='1M')]).count()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = counting(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(['contents','link','Unnamed: 5','Unnamed: 6','Unnamed: 7'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=df2.index,y=df2['title'], line = dict(color='#0B0B61', width=3)))\n",
    "fig.update_layout(title='연월별 뉴스 보도 개수 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기사 제목 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "token = []\n",
    "for sentence in df['title']:\n",
    "    temp_X = []\n",
    "    temp_X = okt.nouns(sentence) # 명사 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    token.append(temp_X)\n",
    "df['token'] = token\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기준에 따른 분류 - 12개 구간으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values('years')\n",
    "\n",
    "import datetime\n",
    "df_1 = df[df['years'] <'2017-04-01'] # 3 / 1,2,3\n",
    "df_2 = df[(df['years']>= '2017-04-01')&(df['years'] <'2017-07-01')] # 3 / 4,5,6\n",
    "df_3 = df[(df['years']>= '2017-07-01')&(df['years'] <'2017-11-01')] # 4 / 7,8,9,10\n",
    "df_4 = df[(df['years']>= '2017-11-01')&(df['years'] <'2018-01-01')] # 2 / 11,12\n",
    "df_5 = df[(df['years']>= '2018-01-01')&(df['years'] <'2018-05-01')] # 4 / 1,2,3,4\n",
    "df_6 = df[(df['years']>= '2018-05-01')&(df['years'] <'2019-02-01')] # 9\n",
    "df_7 = df[(df['years']>= '2019-02-01')&(df['years'] <'2019-10-01')] # 8\n",
    "df_8 = df[(df['years']>= '2019-10-01')&(df['years'] <'2020-01-01')] # 3\n",
    "df_9 = df[(df['years']>= '2020-01-01')&(df['years'] <'2020-05-01')] # 4\n",
    "df_10 = df[(df['years']>= '2020-05-01')&(df['years'] <'2020-08-01')] # 3\n",
    "df_11 = df[(df['years']>= '2020-08-01')&(df['years'] <'2020-11-01')] # 3\n",
    "df_12 = df[df['years']>= '2020-11-01'] # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter # 단어 빈도 수 세기\n",
    "def tokenizing(df):\n",
    "    #konlpy로 명사만 추출하는 토큰화를 진행\n",
    "    words = np.hstack(df['token'].values)\n",
    "    word_count = Counter(words)\n",
    "    #print(word_count.most_common(20))\n",
    "    input = dict(word_count.most_common(300))\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = tokenizing(df_1)\n",
    "df2 = tokenizing(df_2)\n",
    "df3 = tokenizing(df_3)\n",
    "df4 = tokenizing(df_4)\n",
    "df5 = tokenizing(df_5)\n",
    "df6 = tokenizing(df_6)\n",
    "df7 = tokenizing(df_7)\n",
    "df8 = tokenizing(df_8)\n",
    "df9 = tokenizing(df_9)\n",
    "df10 = tokenizing(df_10)\n",
    "df11 = tokenizing(df_11)\n",
    "df12= tokenizing(df_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 워드 클라우드 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 워드클라우드를 그리는 함수 만들기\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "def wcdraw(inputs,width,height,path):\n",
    "    pic = np.array(Image.open(path))\n",
    "    image_colors = ImageColorGenerator(pic)\n",
    "    # 네모 모양으로 wordcloud 생성하기\n",
    "    wordcloud = WordCloud(font_path = 'NanumSquareOTFBold.otf', max_words=40,\n",
    "                          width=width,height=height,background_color ='white',)\n",
    "\n",
    "    # 워드 클라우드 그리기\n",
    "    wordcloud = wordcloud.generate_from_frequencies(inputs)\n",
    "    plt.figure(figsize = (15 , 10))\n",
    "    plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation='bilinear')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#세종시 지도 모양으로 자르기\n",
    "pic = np.array(Image.open('sejong.png'))\n",
    "wordcloud = WordCloud(font_path = 'NanumSquareOTFBold.otf', max_words=300, stopwords = '주택',\n",
    "                        width=2000,height=2500,background_color ='white',colormap = 'ocean',mask = pic)\n",
    "\n",
    "# 워드 클라우드 그리기\n",
    "wordcloud = wordcloud.generate_from_frequencies(tokenizing(df))\n",
    "plt.figure(figsize = (15 , 10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2017년 1월 1일 ~ 3월 31일\n",
    "wcdraw(df1,900,500,'1-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2017년 4월 1일 ~ 7월 31일\n",
    "wcdraw(df2,900,500,'1-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2017년 7월 1일 ~ 10월 31일\n",
    "wcdraw(df3, 1200,500, '1-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2017년 11월 ~ 2017년 12월 31일\n",
    "wcdraw(df4,600,500,'1-4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2018년 1월 ~ 4월 30일\n",
    "wcdraw(df5, 600, 500, '2-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2018년 5월 ~ 2019년 1월 \n",
    "wcdraw(df6, 1350,500,'2-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2019년 2월 ~ 2019년 9월\n",
    "wcdraw(df7, 1200, 500, '2-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2019년 10월 ~ 12월 31일\n",
    "wcdraw(df8, 450, 500, '2-4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 1월 ~ 4월\n",
    "wcdraw(df9, 1200, 500, '3-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 5월 ~ 7월 31일\n",
    "wcdraw(df10, 900, 500, '3-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 8월 ~ 10월 31일\n",
    "wcdraw(df11, 900, 500, '3-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 11월 1일 ~ 12월 31일\n",
    "wcdraw(df12, 600, 500, '3-4.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
