{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 지수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터링 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pydeck 용 coordinates 만들어주기\n",
    "def multipolygon_to_coordinates(x):\n",
    "    lon, lat = x[0].exterior.xy\n",
    "    return [[x, y] for x, y in zip(lon, lat)]\n",
    "\n",
    "data32['coordinates'] = data32['geometry'].apply(multipolygon_to_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시각화 함수\n",
    "def clustermap(df, X, Y):\n",
    "    layer1 = pdk.Layer('ScatterplotLayer', # 사용할 Layer 타입\n",
    "                  df, # 시각화에 쓰일 데이터프레임\n",
    "                  get_position=[X, Y], # geometry 정보를 담고있는 컬럼 이름\n",
    "                  get_color='색상', # 각 데이터 별 rgb 또는 rgba 값 (0~255) # 마지막이 투명도 (0~255사이)\n",
    "                  get_radius=100\n",
    "                  #wireframe=True, # 마우스 오버(hover) 시 박스 출력 \n",
    "                  ) # 3D의 경우 값의 높이를 val 변수를 통해 하겠다.\n",
    "\n",
    "    layer2 = pdk.Layer('PolygonLayer', \n",
    "                       data32, \n",
    "                       get_polygon='coordinates', \n",
    "                       get_fill_color='[100,150,200,30]',\n",
    "                       get_line_color='[255, 255, 255]',\n",
    "                       pickable=True, \n",
    "                       lineWidthScale=15,\n",
    "                       auto_highlight=True)\n",
    "\n",
    "    center = [127.261575, 36.562811]\n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=center[0],\n",
    "        latitude=center[1],\n",
    "        zoom=9.7)\n",
    "\n",
    "    r = pdk.Deck(layers=[layer1,layer2], initial_view_state=view_state,\n",
    "                 mapbox_key ='pk.eyJ1Ijoia3Nra253IiwiYSI6ImNra2NyejlqNzAzamsyb3BtbndvMnVvZjYifQ.xGhIzKCQe1mfade6s__fNw', \n",
    "                 map_style='mapbox://styles/mapbox/dark-v9')\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상권 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HDBSCAN으로 상권 클러스터링\n",
    "clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.0022)\n",
    "df = data14\n",
    "clusterer.fit(df[['lon', 'lat']])\n",
    "df['cluster'] = clusterer.labels_\n",
    "print(len(df['cluster'].unique()))\n",
    "print(len(df[df['cluster'] == -1]))\n",
    "df = df[df['cluster'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "색상 = []\n",
    "for kind in df['cluster']:\n",
    "    np.random.seed(kind + 10000)\n",
    "    \n",
    "    색상_temp = np.random.randint(250, size=(3, )).tolist()\n",
    "    if kind == -1:\n",
    "        색상_temp.extend([0])\n",
    "    else:\n",
    "        색상_temp.extend([170])\n",
    "    \n",
    "    색상.append(색상_temp)\n",
    "    \n",
    "df['색상'] = 색상\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustermap(df, 'lon','lat').to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop = df.groupby('cluster').count()['lon'][df.groupby('cluster').count()['lon'] <= 25].index\n",
    "clustermap(df[~df['cluster'].isin(drop)], 'lon','lat').to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('제거 전: ', len(df['cluster'].unique()))\n",
    "print('제거 후: ', len(df[~df['cluster'].isin(drop)]['cluster'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_delete = df[~df['cluster'].isin(drop)]\n",
    "store_delete = gpd.GeoDataFrame(store_delete, geometry= gpd.points_from_xy(store_delete.lon, store_delete.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#같은 군집에 속하는 좌표들의 합집합을 구하고, 그 합집합의 중점 구하기\n",
    "aca_cluster = {\"cluster\":[],\"lon\":[], \"lat\":[]}\n",
    "\n",
    "for i in list(store_delete.cluster.unique()):\n",
    "    aca_cluster[\"cluster\"].append(i)\n",
    "    aca_cluster[\"lon\"].append(store_delete[store_delete.cluster == i].unary_union.centroid.x)\n",
    "    aca_cluster[\"lat\"].append(store_delete[store_delete.cluster == i].unary_union.centroid.y)\n",
    "    \n",
    "store_cluster_df = pd.DataFrame(aca_cluster)\n",
    "store_cluster_geo = gpd.GeoDataFrame(store_cluster_df, geometry = gpd.points_from_xy(store_cluster_df.lon,store_cluster_df.lat))\n",
    "store_cluster_geo.crs = geo.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학원가 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HDBSCAN으로 학원가 클러스터링\n",
    "clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.003)\n",
    "df = academy \n",
    "clusterer.fit(df[['X', 'Y']])\n",
    "df['cluster'] = clusterer.labels_\n",
    "print(len(df['cluster'].unique()))\n",
    "print(len(df[df['cluster'] == -1]))\n",
    "df = df[df['cluster'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "색상 = []\n",
    "for kind in df['cluster']:\n",
    "    np.random.seed(kind + 10000)\n",
    "    \n",
    "    색상_temp = np.random.randint(250, size=(3, )).tolist()\n",
    "    if kind == -1:\n",
    "        색상_temp.extend([0])\n",
    "    else:\n",
    "        색상_temp.extend([170])\n",
    "    \n",
    "    색상.append(색상_temp)\n",
    "    \n",
    "df['색상'] = 색상\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustermap(df, 'X','Y').to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop = df.groupby('cluster').count()['X'][df.groupby('cluster').count()['X'] <= 20].index\n",
    "clustermap(df[~df['cluster'].isin(drop)], 'X','Y').to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('제거 전: ', len(df['cluster'].unique()))\n",
    "print('제거 후: ', len(df[~df['cluster'].isin(drop)]['cluster'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "academy_delete = df[~df['cluster'].isin(drop)]\n",
    "academy_delete = gpd.GeoDataFrame(academy_delete, geometry= gpd.points_from_xy(academy_delete.X, academy_delete.Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#같은 군집에 속하는 좌표들의 합집합을 구하고, 그 합집합의 중점 구하기\n",
    "aca_cluster = {\"cluster\":[],\"lon\":[], \"lat\":[]}\n",
    "\n",
    "for i in list(academy_delete.cluster.unique()):\n",
    "    aca_cluster[\"cluster\"].append(i)\n",
    "    aca_cluster[\"lon\"].append(academy_delete[academy_delete.cluster == i].unary_union.centroid.x)\n",
    "    aca_cluster[\"lat\"].append(academy_delete[academy_delete.cluster == i].unary_union.centroid.y)\n",
    "    \n",
    "academy_cluster_df = pd.DataFrame(aca_cluster)\n",
    "academy_cluster_geo = gpd.GeoDataFrame(academy_cluster_df, geometry = gpd.points_from_xy(academy_cluster_df.lon,academy_cluster_df.lat))\n",
    "academy_cluster_geo.crs = geo.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지수 생성용 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 별 개수 구해서 추가하는 함수 정의\n",
    "def grid_count(df, name):\n",
    "    df = df.groupby('id').count().reset_index()\n",
    "    df = df[['id','SIG_KOR_NM']]\n",
    "    df.columns = ['id', name]\n",
    "    return df\n",
    "\n",
    "# 그리드 별 평균 구해서 추가하는 함수 정의\n",
    "def grid_mean(df, name):\n",
    "    df = df.groupby('id').mean().reset_index()\n",
    "    df = df[['id','SIG_KOR_NM']]\n",
    "    df.columns = ['id', name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 안전 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 별 가로등 개수 구하기\n",
    "df_light = grid_count(street_lights, '가로등')\n",
    "\n",
    "# 그리드 별 파출소 개수 구하기\n",
    "df_police_office = grid_count(police_office, '파출소')\n",
    "\n",
    "# 그리드 별 cctv 개수 구하기\n",
    "df_cctv = cctv.groupby('id').sum().reset_index()[['id','카메라대수']]\n",
    "df_cctv['카메라대수'] = df_cctv['카메라대수']*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dfs = [geo, df_light, df_police_office, df_cctv]\n",
    "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
    "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)\n",
    "safety = df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통 지수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역, 터미널과의 거리의 경우에는,  \n",
    "- 오송역  \n",
    "- 반석역  \n",
    "- 조치원역  \n",
    "- 세종고속시외버스터미널  \n",
    "- 조치원공영버스터미널   \n",
    "을 고려함\n",
    "\n",
    "제외한 역  \n",
    "- 전의역, 부강역도 하루에 몇 번 정차하지만 이용하기 불편한 횟수  \n",
    "- 전동역, 서창역, 내판역, 매포역, 소정리역은 모든 여객열차가 정차하지 않음  \n",
    "- 청주역: 충북이기도 하고, 사람들이 엄청 다니는 역도 아님.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 별 버스 별 배차 개수 구하기\n",
    "df_bus = bus[['id','BRT','광역버스','지선버스','간선버스','마을버스']]\n",
    "df_bus=df_bus.groupby([\"id\"])['BRT','광역버스','지선버스','간선버스','마을버스'].sum().reset_index()\n",
    "\n",
    "#  그리드 별 중앙 좌표와 가까운 역, 터미널과의 거리 구하기\n",
    "station = pd.read_csv('sejong_stations.csv')\n",
    "station_geo= gpd.GeoDataFrame(station, geometry = gpd.points_from_xy(station.경도, station.위도))\n",
    "station_geo.crs = geo.crs\n",
    "\n",
    "distance_station = []\n",
    "\n",
    "for i in geo['geometry']:\n",
    "    temp = []\n",
    "    for j in station_geo['geometry']:\n",
    "        temp.append(i.distance(j))\n",
    "    \n",
    "    distance_station.append(min(temp)) \n",
    "    \n",
    "station_dist = geo.copy()\n",
    "station_dist[\"역 터미널\"] = distance_station\n",
    "station_dist = station_dist[['id', '역 터미널']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dfs = [geo, df_bus, station_dist]\n",
    "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
    "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 거리가 멀수록 페널티를 주기 위해 Hyperbolic Tangent 도함수에 넣어준 뒤, 정규화를 진행합니다\n",
    "def diff_tanh(x):\n",
    "    return 4/(np.exp(2*x)+2+np.exp(-2*x))\n",
    "\n",
    "dfdf = diff_tanh(df_merge['역 터미널'])\n",
    "\n",
    "dfdf = pd.DataFrame(dfdf, columns=['역 터미널'])\n",
    "df_merge['역 터미널']=dfdf['역 터미널']\n",
    "transport=df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생활 편의 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 별 병원 개수 구하기\n",
    "df_hospital = grid_count(hospital, '병원')\n",
    "\n",
    "# 그리드 별 은행 개수 구하기\n",
    "df_banks = grid_count(banks, '은행')\n",
    "\n",
    "# 그리드 별 학교 개수 구하기\n",
    "df_schools = school.groupby(['id','학교구분']).count().unstack()\n",
    "df_schools = df_schools[df_schools.columns[0:3]].reset_index()\n",
    "df_schools.columns = ['id','고등학교', '중학교', '초등학교']\n",
    "\n",
    "# 그리드 별 공원 개수 구하기\n",
    "df_parks = grid_count(parks, '공원')\n",
    "\n",
    "# 그리드 별 학원 개수 구하기\n",
    "df_academy = grid_count(academy, '학원')\n",
    "\n",
    "# 그리드 별 편의점 개수 구하기\n",
    "df_stores = grid_count(stores, '편의점')\n",
    "\n",
    "# 그리드 별 마트 개수 구하기\n",
    "df_mart = grid_count(mart, '마트')\n",
    "\n",
    "# 그리드 별 약국 개수 구하기\n",
    "df_pharmacy = grid_count(pharmacy, '약국')\n",
    "\n",
    "# 그리드 별 중앙 좌표와 가까운 상권과의 거리 구하기\n",
    "distance_store = []\n",
    "for i in geo['geometry']:\n",
    "    temp = []\n",
    "    for j in store_cluster_geo['geometry']:\n",
    "        temp.append(i.distance(j))\n",
    "    \n",
    "    distance_store.append(min(temp))\n",
    "store_dist = geo.copy()\n",
    "store_dist[\"상권\"] = distance_store\n",
    "store_dist = store_dist[['id', '상권']]\n",
    "\n",
    "\n",
    "# 그리드 별 중앙 좌표와 가까운 학원가와의 거리 구하기\n",
    "distance_academy = []\n",
    "for i in geo['geometry']:\n",
    "    temp = []\n",
    "    for j in academy_cluster_geo['geometry']:\n",
    "        temp.append(i.distance(j))\n",
    "    \n",
    "    distance_academy.append(min(temp)) \n",
    "academy_dist = geo.copy()\n",
    "academy_dist[\"학원가\"] = distance_academy\n",
    "academy_dist = academy_dist[['id', '학원가']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dfs = [geo, df_hospital, df_banks, df_schools, df_parks, df_academy, \n",
    "       df_stores, df_pharmacy, df_mart, store_dist, academy_dist]\n",
    "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
    "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 거리가 멀수록 페널티를 주기 위해 Hyperbolic Tangent 도함수에 넣어준 뒤, 정규화를 진행합니다\n",
    "def diff_tanh(x):\n",
    "    return 4/(np.exp(2*x)+2+np.exp(-2*x))\n",
    "\n",
    "dfdf = diff_tanh(df_merge[['상권','학원가']])\n",
    "df_merge[['상권','학원가']]=dfdf[['상권','학원가']]\n",
    "life = df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 변수 간 존재하는 상관관계를 이용, 이를 대표하는 주성분을 추출하여 차원 축소하는 방법\n",
    "\n",
    "- 각각 요소의 특징을 가장 잘 대변하는 단일 종합 지수 생성을 위해 PCA 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생활지수 \n",
    "\n",
    "- 은행, 초등학교, 중학교, 고등학교, 공원, 학원, 편의점, 약국, 마트, 병원, 그리드별 가까운 상권/학원가와의 직선거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NA 값은 0개이기에, 0으로 입력해준다.\n",
    "life['은행']=life['은행'].fillna(0)\n",
    "life['고등학교']=life['고등학교'].fillna(0)\n",
    "life['중학교']=life['중학교'].fillna(0)\n",
    "life['초등학교']=life['초등학교'].fillna(0) \n",
    "life['공원']=life['공원'].fillna(0)\n",
    "life['학원']=life['학원'].fillna(0)\n",
    "life['편의점']=life['편의점'].fillna(0) \n",
    "life['약국']=life['약국'].fillna(0)\n",
    "life['마트']=life['마트'].fillna(0)\n",
    "life['병원']=life['병원'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
    "id=life['id']\n",
    "\n",
    "# PCA를 위해 x 설정.\n",
    "x=life[['은행','고등학교','중학교','초등학교','공원','학원','편의점','약국','마트','상권','학원가']]\n",
    "\n",
    "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
    "\n",
    "pca= PCA(n_components = 1)\n",
    "PC=pca.fit_transform(x)\n",
    "result1 = pd.DataFrame(PC, columns=['PC1'])\n",
    "result1['id']=id # pca결과에 id 데이터 추가.\n",
    "\n",
    "# PCA PC1값에 minmax scaling을 해주었다. \n",
    "# 이유: 다중회귀분석 \n",
    "min_max_scaler = MinMaxScaler(feature_range=(5,100))\n",
    "x=result1['PC1']\n",
    "x=x.to_numpy(dtype=float)\n",
    "x=x.reshape(-1,1)\n",
    "x1= min_max_scaler.fit_transform(x)\n",
    "result1 = pd.DataFrame(x1, columns=['PC1'])\n",
    "result1['id']=id # pca결과에 id 데이터 추가.\n",
    "life_rate = result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 안전지수\n",
    "\n",
    "- 가로등, 파출소, CCTV 대수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NA 값은 0개이기에, 0으로 채워준다.\n",
    "safety['가로등']=safety['가로등'].fillna(0)\n",
    "safety['파출소']=safety['파출소'].fillna(0)\n",
    "safety['카메라대수']=safety['카메라대수'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
    "id=safety['id']\n",
    "x=safety[['가로등','파출소','카메라대수']]\n",
    "\n",
    "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
    "pca= PCA(n_components = 1)\n",
    "PC=pca.fit_transform(x)\n",
    "result2 = pd.DataFrame(PC, columns=['PC1'])\n",
    "result2['id']=id\n",
    "\n",
    "# PCA PC1값에 minmax scaling을 해주었다. \n",
    "# 이유: 다중회귀분석 \n",
    "x=result2['PC1']\n",
    "x=x.to_numpy(dtype=float)\n",
    "x=x.reshape(-1,1)\n",
    "x1= min_max_scaler.fit_transform(x)\n",
    "result2 = pd.DataFrame(x1, columns=['PC1'])\n",
    "result2['id']=id \n",
    "safety_rate = result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통지수\n",
    "\n",
    "- BRT, 광역, 지선, 간선, 마을버스 기준 그리드별 배차 횟수, 그리드별 중앙 좌표와 가까운 역, 터미널과의 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transport['BRT']=transport['BRT'].fillna(0) # NA값 0으로 대체\n",
    "transport['광역버스']=transport['광역버스'].fillna(0)\n",
    "transport['지선버스']=transport['지선버스'].fillna(0)\n",
    "transport['간선버스']=transport['간선버스'].fillna(0)\n",
    "transport['마을버스']=transport['마을버스'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
    "id=transport['id']\n",
    "x=transport[['BRT','광역버스','지선버스','간선버스','마을버스','역 터미널']]\n",
    "\n",
    "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
    "pca= PCA(n_components = 1)\n",
    "PC=pca.fit_transform(x)\n",
    "result3 = pd.DataFrame(PC, columns=['PC1'])\n",
    "result3['id']=id\n",
    "\n",
    "# PCA PC1값에 minmax scaling을 해주었다. \n",
    "# 이유: 다중회귀분석 \n",
    "min_max_scaler = MinMaxScaler(feature_range=(5,100))\n",
    "x=result3['PC1']\n",
    "x=x.to_numpy(dtype=float)\n",
    "x=x.reshape(-1,1)\n",
    "x1= min_max_scaler.fit_transform(x)\n",
    "result3 = pd.DataFrame(x1, columns=['PC1'])\n",
    "result3['id']=id \n",
    "transport_rate = result3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생활 편의 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
    "pca = pd.merge(life_rate,geo,on='id',how='outer')\n",
    "pca = gpd.GeoDataFrame(pca)\n",
    "\n",
    "plot_grid_map(pca, col = 'PC1', title = '생활 편의 지수', k=12,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Purples', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 안전 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
    "pca = pd.merge(safety_rate,geo,on='id',how='outer')\n",
    "pca = gpd.GeoDataFrame(pca)\n",
    "\n",
    "plot_grid_map(pca, col = 'PC1', title = '안전 지수', k=12,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Greens', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
    "pca = pd.merge(transport_rate,geo,on='id',how='outer')\n",
    "pca = gpd.GeoDataFrame(pca)\n",
    "\n",
    "plot_grid_map(pca, col = 'PC1', title = '교통 지수', k=12,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
