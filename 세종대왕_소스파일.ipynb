{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세종시 주택시장 분석\n",
    "## 팀명: 세종대왕\n",
    "\n",
    "- - -\n",
    "\n",
    "2012년 새롭게 출범한 세종특별자치시는, **'행정중심복합도시'** 라는 우리나라에서 처음으로 시도하는 특별한 형태의 도시입니다.   \n",
    "또한 작년, '세종천도설' 등 여러 이슈에 휩싸이며 주택의 거래량이 가장 빠르게 증가하던 곳이기도 합니다.   \n",
    "그래서 저희는 주어진 데이터를 통해 **세종시의 주택시장이 어떤 특징을 가지고 있는지**를 중심으로 명료한 시각화 모델을 통해 제시하고자 합니다. \n",
    "\n",
    "- - -\n",
    "\n",
    "## 코드 목차\n",
    "\n",
    "### 0. Import\n",
    "  \n",
    "### 1. Data Preprocessing  \n",
    "  \n",
    "- 내부 데이터 전처리    \n",
    "- 외부 데이터 전처리    \n",
    "  \n",
    "### 2. Visualization  \n",
    "  \n",
    "- 시기 별 이슈 확인 (WordCloud)  \n",
    "- 주택 및 거래 관련  \n",
    "- 인구 관련\n",
    "  \n",
    "### 3. Modeling   \n",
    "\n",
    "- 지수 생성  \n",
    "- LDA  \n",
    "- Multiple Regression Analysis  \n",
    "- Oaxaca Decomposition  \n",
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from geoband.API import *\n",
    "import folium\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.5f}'.format\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pydeck as pdk\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "col = px.colors.qualitative.Pastel\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "from pandas import DataFrame\n",
    "import deckgljupyter.Layer as deckgl\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "np.random.seed(seed=42)\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "random.seed(42)\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GetCompasData('SBJ_2102_001', '2', '2.세종시_표제부.csv')\n",
    "GetCompasData('SBJ_2102_001', '3', '3.세종시_아파트(매매)_실거래가.csv')\n",
    "GetCompasData('SBJ_2102_001', '4', '4.세종시_연립다세대(매매)_실거래가.csv')\n",
    "GetCompasData('SBJ_2102_001', '5', '5.세종시_단독다가구(매매)_실거래가.csv')\n",
    "GetCompasData('SBJ_2102_001', '6', '6.세종시_오피스텔(매매)_실거래가.csv')\n",
    "GetCompasData('SBJ_2102_001', '7', '7.세종시_아파트(전월세)_실거래가.csv')\n",
    "GetCompasData('SBJ_2102_001', '8', '8.세종시_연립다세대(전월세)_실거래가.csv')\n",
    "GetCompasData('SBJ_2102_001', '9', '9.세종시_단독다가구(전월세)_실거래가.csv')\n",
    "GetCompasData('SBJ_2102_001', '10', '10.세종시_오피스텔(전월세)_실거래가.csv')\n",
    "GetCompasData('SBJ_2102_001', '14', '14.세종시_상권정보.csv')\n",
    "GetCompasData('SBJ_2102_001', '18', '18.세종시_개별공시지가(2017~2020).csv')\n",
    "GetCompasData('SBJ_2102_001', '19', '19.세종시_연령별_거주인구정보_격자.geojson')\n",
    "GetCompasData('SBJ_2102_001', '20', '20.세종시_전입자수.csv')\n",
    "GetCompasData('SBJ_2102_001', '21', '21.세종시_전출자수.csv')\n",
    "GetCompasData('SBJ_2102_001', '22', '22.세종시_연령별_인구현황.csv')\n",
    "GetCompasData('SBJ_2102_001', '28', '28.세종시_지역별_세대원수별_세대수.csv')\n",
    "GetCompasData('SBJ_2102_001', '29', '29.세종시_거주의사(향후).csv')\n",
    "GetCompasData('SBJ_2102_001', '31', '31.세종시_법정경계(읍면동).geojson')\n",
    "GetCompasData('SBJ_2102_001', '32', '32.세종시_행정경계(읍면동).geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('2.세종시_표제부.csv',encoding='utf-8')\n",
    "data3 = pd.read_csv('3.세종시_아파트(매매)_실거래가.csv', encoding='utf-8')\n",
    "data4 = pd.read_csv('4.세종시_연립다세대(매매)_실거래가.csv',  encoding='utf-8')\n",
    "data5 = pd.read_csv('5.세종시_단독다가구(매매)_실거래가.csv', encoding='utf-8')\n",
    "data6 = pd.read_csv('6.세종시_오피스텔(매매)_실거래가.csv',  encoding='utf-8')\n",
    "data7 = pd.read_csv('7.세종시_아파트(전월세)_실거래가.csv',  encoding='utf-8')\n",
    "data8 = pd.read_csv('8.세종시_연립다세대(전월세)_실거래가.csv', encoding='utf-8')\n",
    "data9 = pd.read_csv('9.세종시_단독다가구(전월세)_실거래가.csv', encoding='utf-8')\n",
    "data10 = pd.read_csv('10.세종시_오피스텔(전월세)_실거래가.csv', encoding='utf-8')\n",
    "data14 = pd.read_csv('14.세종시_상권정보.csv', encoding= 'utf-8')\n",
    "data18 = pd.read_csv('18.세종시_개별공시지가(2017~2020).csv', encoding='utf-8')\n",
    "data19 = gpd.read_file('19.세종시_연령별_거주인구정보_격자.geojson')\n",
    "data20 = pd.read_csv('20.세종시_전입자수.csv', encoding='utf-8')\n",
    "data21 = pd.read_csv('21.세종시_전출자수.csv', encoding='utf-8')\n",
    "data22 = pd.read_csv('22.세종시_연령별_인구현황.csv', encoding='utf-8')\n",
    "data28 = pd.read_csv('28.세종시_지역별_세대원수별_세대수.csv', encoding='utf-8')\n",
    "data29 = pd.read_csv('29.세종시_거주의사(향후).csv', encoding='utf-8')\n",
    "data31 = gpd.read_file('31.세종시_법정경계(읍면동).geojson')\n",
    "data32 = gpd.read_file('32.세종시_행정경계(읍면동).geojson')\n",
    "geo = gpd.read_file('final_geo.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "# 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 매매, 전월세, 공시지가 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지번주소가 다른 방식(ex. 본번, 부번)으로 제공되어있는 \n",
    "\n",
    "  매매(3,4,5,6), 전월세(7,8,9,10), 공시지가(18) raw 데이터를 동일한 지번주소로 통합."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시군구, 본번, 부번 합쳐서 지번주소 만드는 함수 정의\n",
    "\n",
    "def get_address(data):\n",
    "    data = data.reset_index()\n",
    "    df = data\n",
    "    df['부번']=df['부번'].astype(str)\n",
    "    df['본번']=df['본번'].astype(str)\n",
    "    df['시군구']=df['시군구'].astype(str)\n",
    "    \n",
    "    drop = df.loc[(df['본번'] == '0') & (df['부번'] == '0')].index\n",
    "    df = df.drop(drop)\n",
    "    \n",
    "    # 유형 별로 주소 데이터 나누기\n",
    "    df1 = df[df['본번'] == '0'][['index','시군구','본번','부번']]\n",
    "    df2 = df[df['부번'] == '0'][['index','시군구','본번','부번']]\n",
    "    df3 = df.loc[(df['본번'] != '0') & (df['부번'] != '0')][['index','시군구','본번','부번']]\n",
    "    \n",
    "    # 각 유형에 따라 번지 부여\n",
    "    df1['입력주소'] = \" \" + df1['시군구'] + \" \" + df1['부번'] + \"번지\"\n",
    "    df2['입력주소'] = \" \" + df2['시군구'] + \" \" + df2['본번'] + \"번지\"\n",
    "    df3['입력주소'] = \" \" + df3['시군구']+ \" \" + df3['본번'] + \"-\" + df3['부번'] + \"번지\"\n",
    "    \n",
    "    # 3개의 데이터 Merging\n",
    "    from functools import reduce\n",
    "    dfs = [df1,df2,df3]\n",
    "    df_merge = reduce(lambda left, right: \n",
    "                      pd.merge(left, right, on=['index','입력주소'], how='outer'), dfs)\n",
    "    df_merge = df_merge[['index','입력주소']]\n",
    "    df_final = pd.merge(data,df_merge,on = 'index',how='outer')\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 매매, 전월세 데이터 지번주소 뽑아내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 각 데이터에서 지번 주소들 뽑아내기\n",
    "\n",
    "df1 = get_address(data3)[['index','입력주소']]\n",
    "df2 = get_address(data4)[['index','입력주소']]\n",
    "df3 = get_address(data6)[['index','입력주소']]\n",
    "df4 = get_address(data7)[['index','입력주소']]\n",
    "df5 = get_address(data8)[['index','입력주소']]\n",
    "df6 = get_address(data10)[['index','입력주소']]\n",
    "\n",
    "# Data Merging\n",
    "from functools import reduce\n",
    "dfs = [df1,df2,df3,df4,df5,df6]\n",
    "df_merge = reduce(lambda left, right: pd.merge(left, right, on=['index','입력주소'], how='outer'), dfs)\n",
    "\n",
    "df_merge['happy'] = 1\n",
    "df_merge = df_merge[['입력주소','happy']]\n",
    "address = df_merge.drop_duplicates().reset_index()\n",
    "\n",
    "address.to_csv('address.csv', encoding='utf-8') # Geocoding 할 수 있도록 데이터 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공시지가 데이터에서 주택만 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2번 표제부 데이터에서 아파트, 단독주택 데이터만 추출하여 새로운 변수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 공시지가 데이터에서 입력주소, 주소 코드 만들어주기\n",
    "\n",
    "data18['지번'] = data18['지번'].str.replace(\"_\",\"-\")  # 지번 바꾸기\n",
    "data18['입력주소'] = data18['법정동명'] + \" \" + data18['지번'] + \"번지\"\n",
    "data18['법정동코드'] = data18['법정동코드'].astype(str)\n",
    "data18['code'] = data18['법정동코드'] + '/' + data18['지번']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#표제부에서 주택(아파트, 단독) 에 해당하는 지번만 추출하기\n",
    "\n",
    "data2['주용도코드명'] = data2['주용도코드명'].fillna('결측치')\n",
    "house = data2[data2['주용도코드명'].str.contains('주택')] #표제부에서 주택만 추출\n",
    "house['지'] = house['지'].astype(str)\n",
    "house['번'] = house['번'].astype(str)\n",
    "house['법정동코드'] = house['법정동코드'].astype(str)\n",
    "house['시군구코드'] = house['시군구코드'].astype(str)\n",
    "\n",
    "# 지번 변수 만들기\n",
    "drop = house.loc[(house['지'] == '0') & (house['번'] == '0')].index\n",
    "house = house.drop(drop)\n",
    "house1 = house[house['지'] == '0']\n",
    "house2 = house[house['번'] == '0']\n",
    "house3 = house.loc[(house['지'] != '0') & (house['번'] != '0')]\n",
    "house1['지번'] = house1['번']\n",
    "house3['지번'] = house3['번'] + '-' + house3['지']\n",
    "\n",
    "# Data Merging\n",
    "house = pd.concat([house1,house3])\n",
    "house = house[['대지위치','건물명','주용도코드명','시군구코드','법정동코드','지번','사용승인일']]\n",
    "house['code'] = house['시군구코드']+ house['법정동코드'] + '/' + house['지번'] #코드 만들기\n",
    "house = house[['대지위치','주용도코드명','건물명','code','사용승인일']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 표제부 데이터와 공시지가 데이터 합쳐주기 \n",
    "\n",
    "houseonly = pd.merge(data18, house, on = 'code') #주택만 추출된 데이터!\n",
    "houseonly = houseonly[['건물명','법정동명','기준년도','공시지가','대지위치','주용도코드명','사용승인일']]\n",
    "houseonly.to_csv('houseonly.csv', encoding='utf-8') #Geocoding 위해서 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Geocoding 된 데이터들 격자에 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Geocoding Tool을 활용하여, 지번주소를 위경도 좌표 데이터로 변환하는 plus_grid 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 위경도 데이터를 격자로 부여하는 함수 정의\n",
    "\n",
    "def plus_grid(df, geo, X, Y, drop=True):\n",
    "    data1= gpd.GeoDataFrame(df, geometry = gpd.points_from_xy(df[X], df[Y])) #X는 경도, Y는 위도\n",
    "    merge_data = gpd.sjoin(data1, geo, op = \"within\", how = \"right\")\n",
    "    merge_data.crs = geo.crs\n",
    "    if drop:\n",
    "        merge_data = merge_data.dropna()\n",
    "    return merge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  버스정류장 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 세종시 버스정류장 관련 외부 데이터를 활용하여, 하루 배차 회수 1 이하, 정보 누락된 버스정류장 NODE 제외.\n",
    "\n",
    "- plus_grid 함수 사용하여, 그리드 별 개수 COUNT 후 세종시 버스 종류인 BRT, 광역, 지선, 간선, 마을 버스를 column으로 지정\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BUS = pd.read_csv(\"sejong_busnode.csv\", encoding='utf-8') # 버스정류장 데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "TIME=pd.read_csv(\"time.csv\", encoding='utf-8') # 버스 종류별 배차 횟수 데이터버스 종류별 배차 횟수 데이터\n",
    "\n",
    "BUS=BUS.dropna(how=\"all\")\n",
    "\n",
    "#'정류장번호 없음'은 삭제함.\n",
    "index1=BUS[BUS['NODENO']==\"정류장번호 없음\"].index\n",
    "BUS=BUS.drop(index1)\n",
    "# 정류장 번호 '0'은 삭제함\n",
    "index2=BUS[BUS['NODENO']==\"0\"].index\n",
    "BUS=BUS.drop(index2)\n",
    "# index 새롭게 지정\n",
    "BUS=BUS.reset_index()\n",
    "\n",
    "for i in range(0,len(TIME)): # 버스에 따라, 배차 횟수를 hap이라는 열에 지정.\n",
    "    for j in range(0,len(BUS)) :\n",
    "        if BUS['BUS_NUM'][j] == TIME['버스이름'][i]:\n",
    "            BUS['hap'][j] = TIME['개수'][i]\n",
    "\n",
    "# PCA를 통해, 지수를 생성할 것인데 이때의 변수를 버스 종류로 할 것이기에\n",
    "# BUS 데이터에 빈 열을 생성해주었다.\n",
    "BUS['BRT']=\"\"\n",
    "BUS['광역버스']=\"\"\n",
    "BUS['지선버스']=\"\"\n",
    "BUS['간선버스']=\"\"\n",
    "BUS['마을버스']=\"\"\n",
    "\n",
    "BRT=np.array(['B2','900','B5'],dtype=object)\n",
    "광역버스=np.array(['1000','1001','1004','1005'],dtype=object)\n",
    "지선버스=np.array(['11','12','13','52','53','61','201','203','221','300','910'],dtype=object)\n",
    "간선버스=np.array(['430','991'],dtype=object)\n",
    "마을버스=np.array(['16','17','31','32','33','35','62','63','64','65','66','661','67','69','691','71','72','73','74','75','76','81','82','83','84','85','86','91','92','93','94','95'],dtype=object)\n",
    "\n",
    "for i in range(0,len(BUS)):\n",
    "    if BUS[\"BUS_NUM\"][i] in BRT:\n",
    "        BUS['BRT'][i]=BUS['hap'][i]\n",
    "    elif BUS[\"BUS_NUM\"][i] in 광역버스:\n",
    "        BUS['광역버스'][i]=BUS['hap'][i]\n",
    "    elif BUS[\"BUS_NUM\"][i] in 지선버스:\n",
    "        BUS['지선버스'][i]=BUS['hap'][i]\n",
    "    elif BUS[\"BUS_NUM\"][i] in 간선버스:\n",
    "        BUS['간선버스'][i]=BUS['hap'][i]\n",
    "    elif BUS[\"BUS_NUM\"][i] in 마을버스:\n",
    "        BUS['마을버스'][i]=BUS['hap'][i]\n",
    "    else:\n",
    "        print(\"잘못됨\")\n",
    "\n",
    "BUS=BUS[['NODENO','GPSLATI','GPSLONG','BRT','광역버스','지선버스','간선버스','마을버스']]\n",
    "\n",
    "# gpslong 열에 ,가 한 데이터에 포함되어있어 삭제함.\n",
    "BUS['GPSLONG']=BUS['GPSLONG'].astype(str)\n",
    "BUS['GPSLONG'] = BUS['GPSLONG'].str.replace(',', '').astype('float64')\n",
    "\n",
    "# groupby 함수 사용 위해 float으로 변환.\n",
    "BUS['NODENO']=BUS['NODENO'].apply(pd.to_numeric)\n",
    "BUS['GPSLATI']=BUS['GPSLATI'].apply(pd.to_numeric)\n",
    "BUS['GPSLONG']=BUS['GPSLONG'].apply(pd.to_numeric)\n",
    "BUS['BRT']=BUS['BRT'].apply(pd.to_numeric)\n",
    "BUS['광역버스']=BUS['광역버스'].apply(pd.to_numeric)\n",
    "BUS['지선버스']=BUS['지선버스'].apply(pd.to_numeric)\n",
    "BUS['간선버스']=BUS['간선버스'].apply(pd.to_numeric)\n",
    "BUS['마을버스']=BUS['마을버스'].apply(pd.to_numeric)\n",
    "\n",
    "# 버스정류장번호(NODENO)별 \n",
    "BUS1=BUS.groupby([\"NODENO\",\"GPSLATI\",\"GPSLONG\"])['BRT','광역버스','지선버스','간선버스','마을버스'].sum().reset_index()\n",
    "\n",
    "# NODENO는 같지만, GPSLATI와 GPSLONG이 다른 데이터 존재.\n",
    "BUS1=BUS1.drop_duplicates(['NODENO'], keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bus = plus_grid(BUS1, geo, 'GPSLONG', 'GPSLATI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCTV 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_cctv.csv') # CCTV 데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "# CCTV 데이터에서 필요한 컬럼만 추출\n",
    "df = df[['카메라대수','카메라화소수','위도','경도']]\n",
    "\n",
    "cctv = plus_grid(df, geo, '경도', '위도')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가로등 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_light.csv') # 가로등 데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "# 가로등 데이터에서 필요한 컬럼만 추출\n",
    "df = df[['가로등위치명','소재지지번주소','위도','경도']]\n",
    "\n",
    "street_lights = plus_grid(df, geo, '경도', '위도')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파출소 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_policeoffice.csv') # 파출소 데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "# Hospital 데이터에서 필요한 컬럼만 추출\n",
    "df = df[['name','입력주소','X','Y']]\n",
    "\n",
    "police_office = plus_grid(df, geo, 'X', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학교 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_school.csv') # 학교 데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "# 학교 데이터에서 필요한 컬럼만 추출\n",
    "df = df[['학교명','학교구분','주소','X','Y']]\n",
    "\n",
    "school = plus_grid(df, geo, 'X', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공원 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_park.csv') #공원데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "# 공원 데이터에서 필요한 컬럼만 추출\n",
    "df = df[['공원명','소재지지번주소','공원구분','위도','경도']]\n",
    "\n",
    "parks = plus_grid(df, geo, '경도', '위도')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학원 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터를 불러옵니다\n",
    "df = pd.read_csv('sejong_academy.csv') #학원데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "# 학원 데이터에서 필요한 컬럼만 추출\n",
    "academy1 = df[['학원주소','X','Y']]\n",
    "\n",
    "# 상권 데이터에서 학원 데이터를 추출합니다\n",
    "academy2 = data14[data14['상권업종중분류명'].str.contains('학원')]\n",
    "academy2 = academy2.rename({'lon':'X', 'lat':'Y', '도로명주소':'학원주소'}, axis='columns')\n",
    "academy_cat = ['학원(종합)','학원-입시','학원-외국어/어학','학원-어린이영어','태권도장', '피아노/바이올린/기타','합기도장','서예/서화/미술']\n",
    "academy2 = academy2[academy2.상권업종소분류명.isin(academy_cat)][['학원주소','X', 'Y']]\n",
    "\n",
    "# 두 데이터를 합쳐줍니다\n",
    "df = pd.merge(academy1, academy2, on=['X','Y','학원주소'], how='outer')\n",
    "\n",
    "academy = plus_grid(df, geo, 'X', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편의점 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터를 불러옵니다\n",
    "df = data14\n",
    "\n",
    "# 편의점 데이터만 추출합니다\n",
    "df = df[df['상권업종소분류명'].str.contains('편의점')]\n",
    "df = df[['행정동명','도로명주소','lon','lat']]\n",
    "\n",
    "# 편의점 데이터를 격자 데이터에 부여\n",
    "stores = plus_grid(df, geo, 'lon', 'lat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 은행 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_bank.csv') #은행데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "df = df[['name', 'address', '경도','위도']]\n",
    "\n",
    "# 은행 데이터를 격자 데이터에 부여\n",
    "banks = plus_grid(df, geo, '경도', '위도')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 약국 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_pharmacy.csv') #약국데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "df = df[['_약국명칭', '약국소재지 도로명주소', 'X','Y']]\n",
    "\n",
    "# 약국 데이터를 격자 데이터에 부여\n",
    "pharmacy = plus_grid(df, geo, 'X', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_market.csv') #약국데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "df = df[['name', 'address', 'X','Y']]\n",
    "\n",
    "# 약국 데이터를 격자 데이터에 부여\n",
    "mart = plus_grid(df, geo, 'X', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 병원 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('sejong_hospital.csv') # 병원 데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "# Hospital 데이터에서 필요한 컬럼만 추출\n",
    "df = df[['name','입력주소','X','Y']]\n",
    "\n",
    "hospital= plus_grid(df, geo, 'X', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 매매 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 평당 가격 구하는 함수 정의\n",
    "def price_per(df , col='거래금액(만원)'):\n",
    "    df['평'] = df['전용면적(㎡)']/3.3\n",
    "    df['거래금액'] = df[col].str.replace(',','').astype(int)\n",
    "    df['평당가격'] = df['거래금액']/df['평']\n",
    "    df = df.drop(['평',col], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 매매, 전월세 데이터 geocoding 된 데이터\n",
    "adr = pd.read_csv('geoaddress.csv')\n",
    "adr = adr[['입력주소','X','Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = price_per(data3)\n",
    "df4 = price_per(data4)\n",
    "df6 = price_per(data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3 = pd.merge(get_address(df3)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #아파트 매매 데이터에 위경도 추가\n",
    "apt_buy = plus_grid(df3, geo, 'X','Y', drop=False)\n",
    "\n",
    "df4 = pd.merge(get_address(df4)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #연립다세대 매매 데이터에 위경도 추가\n",
    "vil_buy = plus_grid(df4, geo, 'X','Y', drop=False)\n",
    "\n",
    "df6 = pd.merge(get_address(df6)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #오피스텔 매매 데이터에 위경도 추가\n",
    "ops_buy = plus_grid(df6, geo, 'X','Y', drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임대 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전월세 데이터를 전세와 월세로 구분합니다\n",
    "# 1이 전세, 2가 월세\n",
    "\n",
    "df71 = data7[data7['전월세구분'] == '전세']\n",
    "df72 = data7[data7['전월세구분'] == '월세']\n",
    "df81 = data8[data8['전월세구분'] == '전세']\n",
    "df82 = data8[data8['전월세구분'] == '월세']\n",
    "df101 = data10[data10['전월세구분'] == '전세']\n",
    "df102 = data10[data10['전월세구분'] == '월세']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df71 = price_per(df71, col='보증금(만원)')\n",
    "df81 = price_per(df81, col='보증금(만원)')\n",
    "df101 = price_per(df101, col='보증금(만원)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전세 데이터\n",
    "\n",
    "df3 = pd.merge(get_address(df71)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #아파트 매매 데이터에 위경도 추가\n",
    "apt_full = plus_grid(df3, geo, 'X','Y', drop=False)\n",
    "\n",
    "df4 = pd.merge(get_address(df81)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #연립다세대 매매 데이터에 위경도 추가\n",
    "vil_full = plus_grid(df4, geo, 'X','Y', drop=False)\n",
    "\n",
    "df6 = pd.merge(get_address(df101)[['계약년월','평당가격','입력주소','시군구']], adr, on='입력주소') #오피스텔 매매 데이터에 위경도 추가\n",
    "ops_full = plus_grid(df6, geo, 'X','Y', drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 임대(전세+월세) 데이터\n",
    "\n",
    "df3 = pd.merge(get_address(data7)[['계약년월','입력주소','시군구']], adr, on='입력주소') #아파트 매매 데이터에 위경도 추가\n",
    "apt_rent = plus_grid(df3, geo, 'X','Y', drop=False)\n",
    "\n",
    "df4 = pd.merge(get_address(data8)[['계약년월','입력주소','시군구']], adr, on='입력주소') #연립다세대 매매 데이터에 위경도 추가\n",
    "vil_rent = plus_grid(df4, geo, 'X','Y', drop=False)\n",
    "\n",
    "df6 = pd.merge(get_address(data10)[['계약년월','입력주소','시군구']], adr, on='입력주소') #오피스텔 매매 데이터에 위경도 추가\n",
    "ops_rent = plus_grid(df6, geo, 'X','Y', drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공시지가 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('zin18.csv') #Geocoding 데이터\n",
    "df = pd.merge(houseonly, df, left_on = '대지위치', right_on = '지번주소') # 공시지가 데이터\n",
    "geo = gpd.read_file('final_geo.geojson') #격자 데이터\n",
    "\n",
    "df = df[['건물명', '지번주소','기준년도','공시지가', 'X','Y']]\n",
    "\n",
    "# 공시지가 데이터를 격자 데이터에 부여\n",
    "gongsi = plus_grid(df, geo, 'X', 'Y', drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표제부 주택 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Geocoding된 주택 데이터\n",
    "res = pd.concat([pd.read_csv('houseadd_file1.csv'), pd.read_csv('houseadd_file2.csv')])\n",
    "\n",
    "# 주택 데이터를 격자 데이터에 부여\n",
    "reals = plus_grid(res, geo, 'X', 'Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인구 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#거주인구정보 500미터 격자 파일과 합치기\n",
    "grid_500 = geo[['id', 'geometry']]\n",
    "merge19 = gpd.sjoin(grid_500, data19, op='intersects', how = 'left').reset_index()\n",
    "\n",
    "# 중복 제거해주기\n",
    "dropdu = merge19[['gid','201710_20대_거주인구수']].drop_duplicates().index\n",
    "merge19 = merge19.loc[dropdu,:]\n",
    "merge19_group = merge19.groupby('id').sum().reset_index()\n",
    "population = merge19_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "# 2. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) 함수정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- plot_grid_map 함수: QGIS를 활용하여 만든 500X500격자와 주어진 데이터를 id(그리드)별로 통합하여 FisherJenks 이론을 바탕으로 세종특별자치시 지도 위에 단계(k)별로 그리는 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mapclassify as mc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib\n",
    "%config InlineBackend.figure_format='retina' #화질 좋게 해주기\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "nanumr = fm.FontProperties(fname='NanumSquareOTFRegular.otf', size=18)\n",
    "nanumb = fm.FontProperties(fname='NanumSquareOTFBold.otf', size=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_grid_map(df, col, k = 6, title = 'No name', mode = None, cls_dict = None, how = None,\n",
    "                  annotation = False, percen = True, colors = 'Blues', c_mode = 'NaturalBreaks'):\n",
    "    \n",
    "    # 주어진 데이터를 적절히 단계별로 나누는 코드\n",
    "    if mode == 'cont_classify':\n",
    "        dfdf = df[df[col]>0]\n",
    "        if c_mode == 'NaturalBreaks':\n",
    "            quantiles = mc.NaturalBreaks(dfdf[col].dropna(), k = k)\n",
    "        elif c_mode == 'FisherJenks':\n",
    "            quantiles = mc.FisherJenks(dfdf[col].dropna(), k = k)\n",
    "        df['cls_value'] = quantiles.find_bin(df[col]).astype('str')\n",
    "        df.loc[df[col].isnull(), 'cls_value'] = 'No Data'\n",
    "        df.loc[df[col]<0, 'cls_value'] = 'Minus'\n",
    "        cmap = plt.cm.get_cmap(colors, k)\n",
    "        cmap_list = [rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "        if len(np.where(df['cls_value'].unique() == 'Minus')[0]) != 0:\n",
    "            cmap_list.append('#F78181')\n",
    "        if len(np.where(df['cls_value'].unique() == 'No Data')[0]) != 0:\n",
    "            cmap_list.append('#bdbdbd')\n",
    "        cmap_with_grey = ListedColormap(cmap_list)\n",
    "    if mode == 'cluster':\n",
    "        k = len(df[col].unique())\n",
    "        df[col].fillna(-2, inplace=True)\n",
    "        df[col].astype('int')\n",
    "        df['cls_value'] = df[col] + 1\n",
    "        df.sort_values('cls_value')\n",
    "        df.loc[df[col]<0, 'cls_value'] = 'No Data'\n",
    "        cmap = plt.cm.get_cmap(colors, k)\n",
    "        cmap_list = [rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "        if len(np.where(df['cls_value'].unique() == 'No Data')[0]) != 0:\n",
    "            cmap_list.append('#bdbdbd')\n",
    "        cmap_with_grey = ListedColormap(cmap_list)\n",
    "    \n",
    "        \n",
    "    # plot 그리는 코드\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    df.plot(column='cls_value', edgecolor='k', cmap=cmap_with_grey,linewidth=0.05,\n",
    "             legend=True, legend_kwds=dict(loc='upper right'),ax=ax)\n",
    "    \n",
    "    # 범례이름 바꾸는 코드\n",
    "    if mode == 'cont_classify':\n",
    "        legend_labels = ax.get_legend().get_texts()\n",
    "        upper_bounds = quantiles.bins\n",
    "        bounds = []\n",
    "        for index, upper_bound in enumerate(upper_bounds):\n",
    "            if index == 0:\n",
    "                lower_bound = float(df.cls_value.min())\n",
    "            else:\n",
    "                lower_bound = float(upper_bounds[index-1])\n",
    "            \n",
    "            if percen:\n",
    "                bound = '{}% - {}%'.format(round(lower_bound, 1), round(upper_bound, 1))\n",
    "            else:\n",
    "                bound = '{} - {}'.format(round(lower_bound, 2), round(upper_bound, 2))\n",
    "            bounds.append(bound)\n",
    "    if mode == 'cluster':\n",
    "        if 'No Data' in list(df['cls_value'].unique()):\n",
    "            legend_labels = ax.get_legend().get_texts()\n",
    "            bounds = []\n",
    "            for num in list(price_merge['cls_value'].unique())[0:-1]:\n",
    "                bound = 'cluster {}'.format(round(num))\n",
    "                bounds.append(bound)     \n",
    "        else:\n",
    "            legend_labels = ax.get_legend().get_texts()\n",
    "            bounds = []\n",
    "            for num in list(price_merge['cls_value'].unique()):\n",
    "                bound = 'cluster {}'.format(num)\n",
    "                bounds.append(bound)  \n",
    "        \n",
    "    # replace the numerical legend labels\n",
    "    for bound, legend_label in zip(bounds, legend_labels):\n",
    "        legend_label.set_text(bound)\n",
    "        \n",
    "    ax.axis('off')\n",
    "    ax.set_title(title, fontdict={'fontsize': '25', 'fontweight' : '3'} , fontproperties=nanumr)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 색깔 팔레트: https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 시기별 이슈 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시계열로 거래 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# datetime 형태로 바꿔줍니다\n",
    "\n",
    "df3, df4, df5, df6  = data3, data4, data5, data6\n",
    "df7, df8, df9, df10  = data7, data8, data9, data10\n",
    "\n",
    "df3['계약년월'] = pd.to_datetime(df3['계약년월'], format='%Y%m')\n",
    "df4['계약년월'] = pd.to_datetime(df4['계약년월'], format='%Y%m')\n",
    "df5['계약년월'] = pd.to_datetime(df5['계약년월'], format='%Y%m')\n",
    "df6['계약년월'] = pd.to_datetime(df6['계약년월'], format='%Y%m')\n",
    "df7['계약년월'] = pd.to_datetime(df7['계약년월'], format='%Y%m')\n",
    "df8['계약년월'] = pd.to_datetime(df8['계약년월'], format='%Y%m')\n",
    "df9['계약년월'] = pd.to_datetime(df9['계약년월'], format='%Y%m')\n",
    "df10['계약년월'] = pd.to_datetime(df10['계약년월'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전월세 데이터를 전세와 월세로 구분합니다\n",
    "# 1이 전세, 2가 월세\n",
    "\n",
    "df71 = df7[df7['전월세구분'] == '전세']\n",
    "df72 = df7[df7['전월세구분'] == '월세']\n",
    "df81 = df8[df8['전월세구분'] == '전세']\n",
    "df82 = df8[df8['전월세구분'] == '월세']\n",
    "df91 = df9[df9['전월세구분'] == '전세']\n",
    "df92 = df9[df9['전월세구분'] == '월세']\n",
    "df101 = df7[df7['전월세구분'] == '전세']\n",
    "df102 = df7[df7['전월세구분'] == '월세']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 월별로 계약 건수를 세주는 함수를 만듭니다\n",
    "\n",
    "def counting(df):\n",
    "    df = df.set_index('계약년월')\n",
    "    df = df.groupby([pd.Grouper(freq='1M')]).count()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 하나의 데이터프레임으로 합쳐줍니다\n",
    "\n",
    "df = DataFrame()\n",
    "df['apt_m'] = counting(df3)['계약일']\n",
    "df['vil_m'] = counting(df4)['계약일']\n",
    "df['house_m'] = counting(df5)['계약일']\n",
    "df['op_m'] = counting(df6)['계약일']\n",
    "df['apt_j'] = counting(df71)['계약일']\n",
    "df['vil_j'] = counting(df81)['계약일']\n",
    "df['house_j'] = counting(df91)['계약일']\n",
    "df['op_j'] = counting(df101)['계약일']\n",
    "df['apt_w'] = counting(df72)['계약일']\n",
    "df['vil_w'] = counting(df82)['계약일']\n",
    "df['house_w'] = counting(df92)['계약일']\n",
    "df['op_w'] = counting(df102)['계약일']\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['apt'] = df['apt_m'] + df['apt_j'] + df['apt_w']\n",
    "df['vil'] = df['vil_m'] + df['vil_j'] + df['vil_w']\n",
    "df['house'] = df['house_m'] + df['house_j'] + df['house_w']\n",
    "df['op'] = df['op_m'] + df['op_j'] + df['op_w']\n",
    "df['buy'] = df['apt_m'] + df['vil_m'] + df['house_m'] + df['op_m']\n",
    "df['jun'] = df['apt_j'] + df['vil_j'] + df['house_j'] + df['op_j']\n",
    "df['wol'] = df['apt_w'] + df['vil_w'] + df['house_w'] + df['op_w']\n",
    "df['all'] = df['apt'] + df['vil'] + df['house'] + df['op']\n",
    "deal = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세종시 실거래량 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['all'], line = dict(color='#0B0B61', width=3)))\n",
    "fig.update_layout(title='세종시 실거래량 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세종시 거주형태별 실거래량 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['apt'], line = dict(color='#0B0B61', width=3), name='아파트'))\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['vil'], line = dict(color='#404040', width=3), name='연립다세대'))\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['house'], line = dict(color='#F3C706', width=3), name='단독다가구'))\n",
    "fig.add_trace(go.Scatter(x=deal['계약년월'],y=deal['op'], line = dict(color='#0B6121', width=3), name='오피스텔'))\n",
    "fig.update_layout(title='세종시 거주형태별 거래량 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01\n",
    "))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세종시 거래형태별 실거래량 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['buy'], line = dict(color='#0B0B61', width=3), name='매매'))\n",
    "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['jun'], line = dict(color='#0B6121', width=3), name='전세'))\n",
    "fig.add_trace(go.Scatter(x=df['계약년월'],y=df['wol'], line = dict(color='#F3C706', width=3), name='월세'))\n",
    "fig.update_layout(title='세종시 거래형태별 거래량 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    y=0.99,\n",
    "    xanchor=\"left\",\n",
    "    x=0.01\n",
    "))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네이버 뉴스 크롤링 자료 활용 (2017년 1월 ~ 2020년 12월까지, '세종시 부동산' 이라는 키워드로 뉴스 기사 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df2017 = pd.read_csv('sejong2017.csv', encoding= 'utf-8')\n",
    "df2018 = pd.read_csv('sejong2018.csv', encoding= 'utf-8')\n",
    "df2019 = pd.read_csv('sejong2019.csv', encoding= 'utf-8')\n",
    "df2020 = pd.read_csv('sejong2020.csv', encoding= 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data concat\n",
    "df = pd.concat([df2017,df2018,df2019,df2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터 길이 확인\n",
    "print('2017년: ',len(df2017))\n",
    "print('2018년: ',len(df2018))\n",
    "print('2019년: ',len(df2019))\n",
    "print('2020년: ',len(df2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 불용어 설정\n",
    "stopwords = ['않다','에서','있다','없다','그렇다','아니다','것','이다','의','가','이','은','들',\n",
    "             '는','좀','잘','걍','과','도','을','를','으로','자','에','와','한','하다','휴','수','세종시','세종','부동산']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터 한글과 공백을 제외하고 모두 제거\n",
    "df['title'] = df['title'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['title'].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 뉴스 개수 변화 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['years'] = pd.to_datetime(df['years'], format='%Y.%m.%d.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def counting(df):\n",
    "    df = df.set_index('years')\n",
    "    df = df.groupby([pd.Grouper(freq='1M')]).count()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = counting(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2 = df2.drop(['contents','link','Unnamed: 5','Unnamed: 6','Unnamed: 7'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "fig.add_trace(go.Scatter(x=df2.index,y=df2['title'], line = dict(color='#0B0B61', width=3)))\n",
    "fig.update_layout(title='연월별 뉴스 보도 개수 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기사 제목 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "token = []\n",
    "for sentence in df['title']:\n",
    "    temp_X = []\n",
    "    temp_X = okt.nouns(sentence) # 명사 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "    token.append(temp_X)\n",
    "df['token'] = token\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기준에 따른 분류 - 12개 구간으로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.sort_values('years')\n",
    "\n",
    "import datetime\n",
    "df_1 = df[df['years'] <'2017-04-01'] # 3 / 1,2,3\n",
    "df_2 = df[(df['years']>= '2017-04-01')&(df['years'] <'2017-07-01')] # 3 / 4,5,6\n",
    "df_3 = df[(df['years']>= '2017-07-01')&(df['years'] <'2017-11-01')] # 4 / 7,8,9,10\n",
    "df_4 = df[(df['years']>= '2017-11-01')&(df['years'] <'2018-01-01')] # 2 / 11,12\n",
    "df_5 = df[(df['years']>= '2018-01-01')&(df['years'] <'2018-05-01')] # 4 / 1,2,3,4\n",
    "df_6 = df[(df['years']>= '2018-05-01')&(df['years'] <'2019-02-01')] # 9\n",
    "df_7 = df[(df['years']>= '2019-02-01')&(df['years'] <'2019-10-01')] # 8\n",
    "df_8 = df[(df['years']>= '2019-10-01')&(df['years'] <'2020-01-01')] # 3\n",
    "df_9 = df[(df['years']>= '2020-01-01')&(df['years'] <'2020-05-01')] # 4\n",
    "df_10 = df[(df['years']>= '2020-05-01')&(df['years'] <'2020-08-01')] # 3\n",
    "df_11 = df[(df['years']>= '2020-08-01')&(df['years'] <'2020-11-01')] # 3\n",
    "df_12 = df[df['years']>= '2020-11-01'] # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter # 단어 빈도 수 세기\n",
    "def tokenizing(df):\n",
    "    #konlpy로 명사만 추출하는 토큰화를 진행\n",
    "    words = np.hstack(df['token'].values)\n",
    "    word_count = Counter(words)\n",
    "    #print(word_count.most_common(20))\n",
    "    input = dict(word_count.most_common(300))\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = tokenizing(df_1)\n",
    "df2 = tokenizing(df_2)\n",
    "df3 = tokenizing(df_3)\n",
    "df4 = tokenizing(df_4)\n",
    "df5 = tokenizing(df_5)\n",
    "df6 = tokenizing(df_6)\n",
    "df7 = tokenizing(df_7)\n",
    "df8 = tokenizing(df_8)\n",
    "df9 = tokenizing(df_9)\n",
    "df10 = tokenizing(df_10)\n",
    "df11 = tokenizing(df_11)\n",
    "df12= tokenizing(df_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 워드 클라우드 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 워드클라우드를 그리는 함수 만들기\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "def wcdraw(inputs,width,height,path):\n",
    "    pic = np.array(Image.open(path))\n",
    "    image_colors = ImageColorGenerator(pic)\n",
    "    # 네모 모양으로 wordcloud 생성하기\n",
    "    wordcloud = WordCloud(font_path = 'NanumSquareOTFBold.otf', max_words=40,\n",
    "                          width=width,height=height,background_color ='white',)\n",
    "\n",
    "    # 워드 클라우드 그리기\n",
    "    wordcloud = wordcloud.generate_from_frequencies(inputs)\n",
    "    plt.figure(figsize = (15 , 10))\n",
    "    plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation='bilinear')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#세종시 지도 모양으로 자르기\n",
    "pic = np.array(Image.open('sejong.png'))\n",
    "wordcloud = WordCloud(font_path = 'NanumSquareOTFBold.otf', max_words=300, stopwords = '주택',\n",
    "                        width=2000,height=2500,background_color ='white',colormap = 'ocean',mask = pic)\n",
    "\n",
    "# 워드 클라우드 그리기\n",
    "wordcloud = wordcloud.generate_from_frequencies(tokenizing(df))\n",
    "plt.figure(figsize = (15 , 10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2017년 1월 1일 ~ 3월 31일\n",
    "wcdraw(df1,900,500,'1-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2017년 4월 1일 ~ 7월 31일\n",
    "wcdraw(df2,900,500,'1-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2017년 7월 1일 ~ 10월 31일\n",
    "wcdraw(df3, 1200,500, '1-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2017년 11월 ~ 2017년 12월 31일\n",
    "wcdraw(df4,600,500,'1-4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2018년 1월 ~ 4월 30일\n",
    "wcdraw(df5, 600, 500, '2-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2018년 5월 ~ 2019년 1월 \n",
    "wcdraw(df6, 1350,500,'2-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2019년 2월 ~ 2019년 9월\n",
    "wcdraw(df7, 1200, 500, '2-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2019년 10월 ~ 12월 31일\n",
    "wcdraw(df8, 450, 500, '2-4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 1월 ~ 4월\n",
    "wcdraw(df9, 1200, 500, '3-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 5월 ~ 7월 31일\n",
    "wcdraw(df10, 900, 500, '3-2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 8월 ~ 10월 31일\n",
    "wcdraw(df11, 900, 500, '3-3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 11월 1일 ~ 12월 31일\n",
    "wcdraw(df12, 600, 500, '3-4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 주택 및 거래 관련"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주택 나이 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 주택 나이 나타내는 column 추가\n",
    "df = pd.merge(house,res,on='대지위치',how='right')[['X','Y','사용승인일']]\n",
    "df = df.dropna()\n",
    "df['사용연도'] = df['사용승인일'].astype(str).str[:4]\n",
    "df['사용연도'] = 2022 - df['사용연도'].astype(int)\n",
    "\n",
    "# 그리드 별 평균 구해주기\n",
    "df = plus_grid(df, geo, 'X', 'Y').groupby('id').mean()\n",
    "df = pd.merge(df,geo,on='id',how='outer')\n",
    "df = GeoDataFrame(df)\n",
    "age = df[['id','사용연도']].fillna(0)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df, col = '사용연도', title = '건축 연한', k=10,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Purples', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주택 매매 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "col = ['id','계약년월','평당가격','geometry','입력주소']\n",
    "dfs = [apt_buy[col],vil_buy[col],ops_buy[col]]\n",
    "buy = reduce(lambda left, right: pd.merge(left, right, on=col, how='outer'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 상승장 이전 이후로 나누기\n",
    "before1 = buy.loc[buy['계약년월']<201910] #상승장 이전\n",
    "after1 = buy[buy['계약년월']>201909] #상승장 이후\n",
    "\n",
    "# 그리드 당 평균 매매 가격구하기\n",
    "before = DataFrame(before1.groupby(['id']).mean()['평당가격']).reset_index()\n",
    "after = DataFrame(after1.groupby(['id','계약년월']).mean()['평당가격']).reset_index()\n",
    "all = DataFrame(buy.groupby(['id','계약년월']).mean()['평당가격']).reset_index()\n",
    "\n",
    "# datetime으로 바꾸기\n",
    "from datetime import datetime\n",
    "after['계약년월'] = pd.to_datetime(after['계약년월'], format='%Y%m')\n",
    "all['계약년월'] = pd.to_datetime(all['계약년월'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all.to_csv('grid_price.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 추이 간단히 시각화\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in all['id'].unique().tolist():\n",
    "    d_ = all[(all[\"id\"]==i)]\n",
    "    plt.plot(d_[\"계약년월\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('매매 가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상승장 이전 매매 가격 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_before = pd.merge(before,geo,on='id',how='outer')\n",
    "df_before = GeoDataFrame(df_before)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df_before, # 데이터: 격자 - 수치변수 이렇게 두개만 들어와 있는 GeoDataFrame 형태여야함\n",
    "              col = '평당가격', # 수치변수 들어와있는 컬럼명\n",
    "              title = '상승장 이전 매매가격 평균', # 시각화에 붙이고 싶은 제목 \n",
    "              k =10, # 수치변수를 몇단계로 나누고 싶은지\n",
    "              mode = 'cont_classify', #FisherJenks나 NaturalBreaks(KMeans) 쓸거면 얘 그냥 적으면 됨\n",
    "              c_mode = 'FisherJenks', #케이민즈 쓰고 싶으면 NaturalBreaks 쓰기\n",
    "              colors = 'Greens', #쓰고 싶은 색깔,, Blues Greens Purples 등등 다 가능함\n",
    "              percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 매매 거래 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = buy.dropna()\n",
    "df = df.groupby('id').count().reset_index()[['id','평당가격']]\n",
    "df = pd.merge(df,geo,on='id',how='outer')\n",
    "df = GeoDataFrame(df)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df, col = '평당가격', title = '매매 거래 건수', k=10,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = before1.dropna()\n",
    "df = df.groupby('id').count().reset_index()[['id','평당가격']]\n",
    "df = pd.merge(df,geo,on='id',how='outer')\n",
    "df = GeoDataFrame(df)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df, col = '평당가격', title = '상승장 이전 매매 거래 건수', k=10,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = after1.dropna()\n",
    "df = df.groupby('id').count().reset_index()[['id','평당가격']]\n",
    "df = pd.merge(df,geo,on='id',how='outer')\n",
    "df = GeoDataFrame(df)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df, col = '평당가격', title = '상승장 이후 매매 거래 건수', k=10,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 매매 실거래가 추이 Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#그리드 당 매매가격 불러오기\n",
    "grid_price = all.copy()\n",
    "\n",
    "#계약년월 열에 날짜 속성 부여 \n",
    "grid_price_n = grid_price.set_index('계약년월')\n",
    "\n",
    "#1년 단위로 자료 resampling\n",
    "grid_price_y = grid_price_n.groupby('id')['평당가격'].resample('Y').mean().reset_index()\n",
    "grid_price_y['year'] = grid_price_y['계약년월'].dt.year\n",
    "\n",
    "df1 = grid_price_y.pivot(index='id', columns='year', values='평당가격').reset_index()\n",
    "\n",
    "#결측치 3개 이상인 값 drop\n",
    "df1.dropna(thresh=3, inplace=True)\n",
    "\n",
    "#결측치 0으로 대체\n",
    "df1.fillna(0, inplace=True)\n",
    "value = df1.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#AgglomerativeClustering을 이용하여, 7개의 군집으로 clustering\n",
    "cluster_price = AgglomerativeClustering(n_clusters=7, affinity='euclidean', linkage='ward')\n",
    "cluster_price.fit_predict(value)\n",
    "df1[\"cluster\"] = cluster_price.fit_predict(value)\n",
    "df2 = pd.melt(df1, id_vars=['id'], value_vars=df1.iloc[:,1:-1], value_name='평당가격')\n",
    "df3 = df1[['id', 'cluster']]\n",
    "df4 = pd.merge(df2, df3, on = 'id', how = 'left')\n",
    "\n",
    "#연도만 따로 추출한 year 열에 날짜 속성 부여\n",
    "df4['year'] = pd.to_datetime(df4['year'], format='%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#군집 순서를 완만->급격 순으로 임의 조정\n",
    "df4['cluster_n'] = df4['cluster'] + 10\n",
    "df4['cluster_n'].replace(to_replace=[10,11,12,13,14,15,16], value= [0,2,6,3,1,5,4], inplace=True)\n",
    "df4 = df4.drop(['cluster'], axis=1)\n",
    "df4.rename(columns = {'cluster_n':'cluster'}, inplace=True)\n",
    "\n",
    "#군집 순서를 완만->급격 순으로 임의 조정\n",
    "df_price = df1[['id', 'cluster']]\n",
    "df_price['cluster_n'] = df_price['cluster'] + 10\n",
    "df_price['cluster_n'].replace(to_replace=[10,11,12,13,14,15,16], value= [0,2,6,3,1,5,4], inplace=True)\n",
    "df_price = df_price.drop(['cluster'], axis=1)\n",
    "df_price.rename(columns = {'cluster_n':'cluster'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터 별 plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#군집1 plot\n",
    "cluster_1 = df4[df4['cluster'] == 0]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in cluster_1['id'].unique().tolist():\n",
    "    d_ = cluster_1[(cluster_1[\"id\"]==i)]\n",
    "    plt.plot(d_[\"year\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('군집1_매매가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#군집2 plot\n",
    "cluster_2 = df4[df4['cluster'] == 1]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in cluster_2['id'].unique().tolist():\n",
    "    d_ = cluster_2[(cluster_2[\"id\"]==i)]\n",
    "    plt.plot(d_[\"year\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('군집2_매매가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#군집3 plot\n",
    "cluster_3 = df4[df4['cluster'] == 2]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in cluster_3['id'].unique().tolist():\n",
    "    d_ = cluster_3[(cluster_3[\"id\"]==i)]\n",
    "    plt.plot(d_[\"year\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('군집3_매매가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#군집4 plot\n",
    "cluster_4 = df4[df4['cluster'] == 3]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in cluster_4['id'].unique().tolist():\n",
    "    d_ = cluster_4[(cluster_4[\"id\"]==i)]\n",
    "    plt.plot(d_[\"year\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('군집4_매매가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#군집5 plot\n",
    "cluster_5 = df4[df4['cluster'] == 4]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in cluster_5['id'].unique().tolist():\n",
    "    d_ = cluster_5[(cluster_5[\"id\"]==i)]\n",
    "    plt.plot(d_[\"year\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('군집5_매매가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#군집6 plot\n",
    "cluster_6 = df4[df4['cluster'] == 5]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in cluster_6['id'].unique().tolist():\n",
    "    d_ = cluster_6[(cluster_6[\"id\"]==i)]\n",
    "    plt.plot(d_[\"year\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('군집6_매매가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#군집7 plot\n",
    "cluster_7 = df4[df4['cluster'] == 6]\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in cluster_7['id'].unique().tolist():\n",
    "    d_ = cluster_7[(cluster_7[\"id\"]==i)]\n",
    "    plt.plot(d_[\"year\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('군집7_매매가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#격자 데이터와 병합\n",
    "price_merge = pd.merge(df_price, geo, on = 'id', how = 'right')\n",
    "\n",
    "#cluster 순서에 따라 데이터 정렬\n",
    "price_merge.sort_values('cluster', inplace=True)\n",
    "\n",
    "#geodataframe으로 변환\n",
    "price_merge = gpd.GeoDataFrame(price_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plot_grid_map(price_merge, col = 'cluster', title = '평당가격 클러스터링', mode = 'cluster',\n",
    "              c_mode = 'NaturalBreaks', colors = 'Blues', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주택 전세 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "col = ['id','계약년월','평당가격','geometry','입력주소']\n",
    "dfs = [apt_full[col],vil_full[col],ops_full[col]]\n",
    "full = reduce(lambda left, right: pd.merge(left, right, on=col, how='outer'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 당 평균 전세 가격구하기\n",
    "df = DataFrame(full.groupby(['id','계약년월']).mean()['평당가격']).reset_index()\n",
    "\n",
    "# datetime으로 바꾸기\n",
    "from datetime import datetime\n",
    "df['계약년월'] = pd.to_datetime(df['계약년월'], format='%Y%m')\n",
    "\n",
    "# 추이 간단히 시각화\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in df['id'].unique().tolist():\n",
    "    d_ = df[(df[\"id\"]==i)]\n",
    "    plt.plot(d_[\"계약년월\"], d_[\"평당가격\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.title('전세 가격 추이', fontproperties=nanumr)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주택 임대 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "col = ['id','계약년월', 'geometry','입력주소']\n",
    "dfs = [apt_rent[col],vil_rent[col],ops_rent[col]]\n",
    "rent = reduce(lambda left, right: pd.merge(left, right, on=col, how='outer'), dfs)\n",
    "before2 = rent[rent['계약년월']<201910] #상승장 이전\n",
    "after2 = rent[rent['계약년월']>201909] #상승장 이후"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 당 평균 임대 건수구하기\n",
    "df = DataFrame(rent.groupby(['id','계약년월']).count()['입력주소']).reset_index()\n",
    "\n",
    "# datetime으로 바꾸기\n",
    "from datetime import datetime\n",
    "df['계약년월'] = pd.to_datetime(df['계약년월'], format='%Y%m')\n",
    "\n",
    "# 추이 간단히 시각화\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in df['id'].unique().tolist():\n",
    "    d_ = df[(df[\"id\"]==i)]\n",
    "    plt.plot(d_[\"계약년월\"], d_[\"입력주소\"], \"-\", alpha=.6)\n",
    "plt.grid()\n",
    "plt.legend(fontsize=13)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 임대 거래 건수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = rent.dropna()\n",
    "df = df.groupby('id').count().reset_index()[['id','입력주소']]\n",
    "df = pd.merge(df,geo,on='id',how='outer')\n",
    "df = GeoDataFrame(df)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df, col = '입력주소', title = '임대 거래 건수', mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = before2.dropna()\n",
    "df = df.groupby('id').count().reset_index()[['id','입력주소']]\n",
    "df = pd.merge(df,geo,on='id',how='outer')\n",
    "df = GeoDataFrame(df)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df, col = '입력주소', title = '상승장 이전 임대 거래 건수', mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = after2.dropna()\n",
    "df = df.groupby('id').count().reset_index()[['id','입력주소']]\n",
    "df = pd.merge(df,geo,on='id',how='outer')\n",
    "df = GeoDataFrame(df)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df, col = '입력주소', title = '상승장 이후 임대 거래 건수', mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 행정동별 전세가율 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 아파트 데이터만 불러오기\n",
    "aptb = apt_buy.dropna()\n",
    "aptf = apt_full.dropna()\n",
    "aptb['시군구'] = aptb['시군구'].str[8:11]\n",
    "aptf['시군구'] = aptf['시군구'].str[8:11]\n",
    "\n",
    "# 날짜 별로 정렬\n",
    "aptf = DataFrame(aptf.groupby(['시군구','입력주소','계약년월']).mean()['평당가격']).reset_index()\n",
    "aptb = DataFrame(aptb.groupby(['시군구','입력주소','계약년월']).mean()['평당가격']).reset_index()\n",
    "\n",
    "df2 = pd.merge(aptb, aptf, on=['시군구','입력주소', '계약년월'], how='outer')\n",
    "df2['전세가율'] = 100*df2['평당가격_y']/df2['평당가격_x']\n",
    "df2['계약년월'] = pd.to_datetime(df2['계약년월'], format='%Y%m')\n",
    "\n",
    "df2 = df2.dropna().groupby(['시군구', '계약년월']).mean().unstack()['전세가율'].transpose()\n",
    "\n",
    "# 시각화\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "for i in df2.columns.tolist():\n",
    "    fig.add_trace(go.Scatter(x=df2.index,y=df2[i],\n",
    "             mode='lines', name=i))\n",
    "fig.update_layout(title='세종시 전세가율 추이', plot_bgcolor='#F8F7F1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Merging\n",
    "df2 = DataFrame(df2.mean()).reset_index()\n",
    "df2 = df2.replace('조치원','조치원읍')\n",
    "df2 = pd.merge(df2,data31,left_on='시군구',right_on='EMD_KOR_NM',how='outer')\n",
    "df2 = GeoDataFrame(df2)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df2, col = 0, title = '전세가율',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'Blues', percen = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 공시지가 변동률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 연도별 공시지가 변동률 구하기\n",
    "\n",
    "df = gongsi.groupby(['지번주소','id','기준년도']).mean()['공시지가'].unstack()\n",
    "df = df.dropna(thresh=2)\n",
    "df = df.reset_index()\n",
    "\n",
    "# 변동률이기에 로그 근사 시켜주기\n",
    "\n",
    "df['17-18'] = (df[2018.0] - df[2017.0])/df[2017.0] +1\n",
    "df['18-19'] = (df[2019.0] - df[2018.0])/df[2018.0] +1\n",
    "df['19-20'] = (df[2020.0] - df[2019.0])/df[2019.0] +1\n",
    "\n",
    "df[['17-18','18-19','19-20']] = np.log(df[['17-18','18-19','19-20']])\n",
    "df[[2017.0, 2018.0, 2019.0, 2020.0]] = df[[2017.0, 2018.0, 2019.0, 2020.0]]*3.3/10000\n",
    "df.fillna(0)\n",
    "df['변동률'] = (df['17-18'] + df['18-19'] + df['19-20'])*100/3\n",
    "gongsi2 = df.groupby('id').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gongsi2 = pd.merge(gongsi2,geo,on='id',how='outer')\n",
    "df2 = GeoDataFrame(gongsi2)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df2, col = '변동률', title = '공시지가 변동률',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'BuGn', percen = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020년 공시지가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plot_grid_map(df2, col = 2020.0, title = '2020년 공시지가',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'BuGn', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 인구 관련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = population.set_index('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 청년층 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2020년 데이터만 추출\n",
    "\n",
    "df2020 = df[['202010_20대_거주인구수','202010_30대_거주인구수','202010_40대_거주인구수',\n",
    "        '202010_50대_거주인구수','202010_60대_거주인구수','202010_70대_거주인구수',\n",
    "        '202010_80대_거주인구수','202010_90대_거주인구수','202010_100세이상_거주인구수']].fillna(0)\n",
    "\n",
    "# 청년층 비율 계산\n",
    "df2020['총합'] = df2020.sum(axis=1)\n",
    "df2020['청년층비율'] = 100*(df2020['202010_20대_거주인구수']+df2020['202010_30대_거주인구수'])/df2020['총합']\n",
    "df2020['노년층비율'] = 100*(df2020['202010_70대_거주인구수']+df2020['202010_80대_거주인구수']+\n",
    "                       df2020['202010_90대_거주인구수']+df2020['202010_100세이상_거주인구수'])/df2020['총합']\n",
    "df2020 = df2020.reset_index()\n",
    "\n",
    "# 시각화\n",
    "df2020 = pd.merge(df2020,geo,on='id',how='outer')\n",
    "df2020 = GeoDataFrame(df2020)\n",
    "plot_grid_map(df2020, col = '청년층비율' , title = '청년층',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'YlGn', percen = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop2020 = df2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 노년층 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plot_grid_map(df2020, col = '노년층비율' , title = '노년층',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'YlGn', percen = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전입자 수, 전출자 수 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전입자 수 데이터\n",
    "dfin = data20.groupby(['년월','세종전입행정동']).sum().unstack()\n",
    "dfin.columns = dfin.columns.droplevel(0)\n",
    "dfin = dfin.rename_axis(None, axis=1).fillna(0)\n",
    "\n",
    "# 전출자 수 데이터\n",
    "dfout = data21.groupby(['년월','세종전출행정동']).sum().unstack()\n",
    "dfout.columns = dfout.columns.droplevel(0)\n",
    "dfout = dfout.rename_axis(None, axis=1).fillna(0)\n",
    "\n",
    "# 인덱스 datetime 으로 변환\n",
    "dfin.index = pd.to_datetime(dfin.index, format='%Y%m')\n",
    "dfout.index = pd.to_datetime(dfout.index, format='%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#동별 순 전입자수 시각화\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "df= dfin - dfout\n",
    "fig = make_subplots(rows=1, cols=1, shared_xaxes=True)\n",
    "for i in df.columns.tolist():\n",
    "    fig.add_trace(go.Scatter(x=df.index,y=df[i],\n",
    "             mode='lines', name=i))\n",
    "fig.update_layout(title='순 유입(전입자 수 - 전출자 수)', plot_bgcolor='#F8F7F1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내지인 거래 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전출 동네가 세종시인 비율 구하기\n",
    "data20['전출 동네'] = data20['전출시군구'] + ' ' + data20['전출읍면동']\n",
    "df = data20.groupby(['세종전입행정동','전출시군구']).sum()['전입자수'].unstack().transpose().fillna(0)\n",
    "df2 = df.transpose()\n",
    "df2['세종비율'] = 100*df.loc['세종특별자치시']/df.sum()\n",
    "df = DataFrame(df2['세종비율']).reset_index()\n",
    "\n",
    "# Data Merging\n",
    "df2 = pd.merge(df,data32,left_on='세종전입행정동',right_on='ADM_DR_NM',how='outer')\n",
    "df2 = GeoDataFrame(df2)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df2, col = '세종비율', title = '세종시 전입 비율',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'YlGn', percen = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전출시도별 전입자수 추이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전출시도별 전입자수 추이\n",
    "data20_2 = data20.groupby([\"년월\",\"전출시\"]).count().reset_index()\n",
    "data20_2['년월'] = pd.to_datetime(data20_2['년월'], format='%Y%m')\n",
    "\n",
    "table = data20_2.pivot_table(index = ['년월'],columns=['전출시'])\n",
    "provinces = data20_2['전출시'].unique()\n",
    "\n",
    "fig = make_subplots(rows=6, cols=3,horizontal_spacing=0.05,subplot_titles=([f'<b>{prov}</b>' for prov in provinces]))\n",
    "\n",
    "for i, province in enumerate(provinces):\n",
    "    row, col, legend = i//3 + 1, i%3 + 1, False\n",
    "    if i == len(provinces)-1 :\n",
    "        legend = True\n",
    "    fig.add_trace(go.Scatter(x=table.index,y= table['전입자수'][province],\n",
    "                 mode='lines', name=col,showlegend=False), row=row, col=col)\n",
    "\n",
    "fig.update_layout(title='<b>시도별 세종시 전입자수 추이</b>',\n",
    "                  height = 2000,\n",
    "                  legend=dict(x=0.7, y=0.05, traceorder=\"normal\",\n",
    "                             font=dict(family=\"sans-serif\", size=18)), plot_bgcolor='#F8F7F1')    \n",
    "for i in fig['layout']['annotations']:\n",
    "    i['font'] = dict(size=9)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data20_2 = data20_2.groupby('년월').sum().reset_index()\n",
    "fig = px.bar(data20_2,x='년월',y = '전입자수', color_discrete_sequence=['navy'])\n",
    "fig.update_layout(title='<b>전출시도별 전입자수 추이</b>', plot_bgcolor='#F8F7F1')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 순 전입자 수 구하기\n",
    "df = dfin - dfout\n",
    "df = DataFrame(df.sum()).reset_index()\n",
    "\n",
    "# Data Merging\n",
    "df2 = pd.merge(df,data32,left_on='index',right_on='ADM_DR_NM',how='outer')\n",
    "df2 = GeoDataFrame(df2)\n",
    "popin = df2\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df2, col = 0 , title = '세종시 순전입자 수',mode = 'cont_classify', k=3,\n",
    "              c_mode = 'FisherJenks', colors = 'YlGn', percen = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전입/전출 비율 구하기\n",
    "df = 100*dfin.sum()/dfout.sum()\n",
    "df = DataFrame(df).reset_index()\n",
    "\n",
    "# Data Merging\n",
    "df2 = pd.merge(df,data32,left_on='index',right_on='ADM_DR_NM',how='outer')\n",
    "df2 = GeoDataFrame(df2)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df2, col = 0 , title = '세종시 전입 전출 비율',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'YlGn', percen = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읍면동 별 인구 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data22[['읍면동','202012_남자(총_거주자_수)','202012_여자(총_거주자_수)']]\n",
    "emd = []\n",
    "for i in range(len(df)):\n",
    "    if df['읍면동'][i][2] == '면':\n",
    "        emd.append('면')\n",
    "    elif df['읍면동'][i][2] == '원':\n",
    "        emd.append('읍')\n",
    "        \n",
    "    elif df['읍면동'][i][2] == '동':\n",
    "        emd.append('동')\n",
    "    else:\n",
    "        emd.append('세종')\n",
    "df['emd'] = emd\n",
    "df['계'] = df['202012_남자(총_거주자_수)']+df['202012_여자(총_거주자_수)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfdf = df.drop(0)\n",
    "dfdf = dfdf.groupby('emd').sum().reset_index()\n",
    "labels = dfdf['emd']\n",
    "values = dfdf['계']\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3, marker_colors=['#F5D042', '#0A174E', '#09663D'])])\n",
    "fig.update_layout(legend=dict(xanchor=\"left\",x=0.65),title='세종시 인구 수 비율',font=dict(size=18))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = ['남자', '여자']\n",
    "values = [176998, 177707]\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3, marker_colors=['b', 'r'])])\n",
    "fig.update_layout(legend=dict(xanchor=\"left\",x=0.65),title='세종시 인구 수 비율',font=dict(size=18))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읍면동 별 가구 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 읍면동으로 나누기\n",
    "df = data28\n",
    "df['읍면동'] = df['읍면동'].str.replace(\" \", \"\") # 공백 제거\n",
    "\n",
    "emd = []\n",
    "for i in range(len(df)):\n",
    "    if df['읍면동'][i][2] == '면':\n",
    "        emd.append('면')\n",
    "    elif df['읍면동'][i][2] == '원':\n",
    "        emd.append('읍')\n",
    "    elif df['읍면동'][i][2] == '동':\n",
    "        emd.append('동')\n",
    "df['emd'] = emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "dfdf = df.groupby('emd').sum().reset_index()\n",
    "labels = dfdf['emd']\n",
    "values = dfdf['계']\n",
    "\n",
    "# Use `hole` to create a donut-like pie chart\n",
    "fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3, marker_colors=['#F5D042', '#0A174E', '#09663D'])])\n",
    "fig.update_layout(legend=dict(xanchor=\"left\",x=0.65), title='세종시 가구 수 비율',font=dict(size=18))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1인 가구 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data28\n",
    "df['읍면동'] = df['읍면동'].str.replace(\" \", \"\") # 공백 제거\n",
    "\n",
    "# 1인가구 비율 구하기\n",
    "df['1인가구 비율'] = 100*df['1인']/df['계']\n",
    "\n",
    "# 핵가족\n",
    "df['핵가족 비율'] = 100*(df['2인']+df['3인']+df['5인'])/df['계']\n",
    "\n",
    "# 대가족\n",
    "df['대가족 비율'] = 100*(df['6인']+df['7인']+df['8인']+df['9인']+df['10인이상'])/df['계']\n",
    "\n",
    "# Data Merging\n",
    "df2 = pd.merge(df,data32,left_on='읍면동',right_on='ADM_DR_NM',how='outer')\n",
    "df2 = GeoDataFrame(df2)\n",
    "\n",
    "# 시각화\n",
    "plot_grid_map(df2, col = '1인가구 비율' , title = '1인 가구 비율',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'YlGn', percen = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 핵가족 가구 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plot_grid_map(df2, col = '핵가족 비율' , title = '핵가족 가구 비율',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'YlGn', percen = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대가족 가구 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시각화\n",
    "plot_grid_map(df2, col = '대가족 비율' , title = '대가족 가구 비율',mode = 'cont_classify', k=10,\n",
    "              c_mode = 'FisherJenks', colors = 'YlGn', percen = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 거주 의사 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat29 = data29.copy()\n",
    "dat29['긍정'] =  data29['매우 그런편임']+ data29['어느정도 그런편임']\n",
    "dat29['부정'] =  data29['약간 그렇지 않은편임']+ data29['전혀 그렇지 않은편임']\n",
    "dat29 = dat29.drop(['매우 그런편임','어느정도 그런편임','전혀 그렇지 않은편임','약간 그렇지 않은편임'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 데이터, 변수별 분리\n",
    "data29_dur = dat29.loc[6:7] # 거주기간별\n",
    "data29_mar = dat29.loc[25:27] # 결혼여부별 \n",
    "data29_hom = dat29.loc[38:40] # 주거점유형태별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 거주기간별 향후 거주 의사 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data29_dur.transpose().reset_index().drop([0,1])\n",
    "for i in range(2):\n",
    "    # Use `hole` to create a donut-like pie chart\n",
    "    fig = go.Figure(data=[go.Pie(labels=df['index'], values=df[i+6], hole=.4, marker_colors=['#F5D042', '#0A174E', '#09663D'])])\n",
    "    fig.update_layout(legend=dict(xanchor=\"left\",x=0.65), title='향후 거주 의사',font=dict(size=18))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주거점유형태별 향후 거주 의사 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = data29_hom.transpose().reset_index().drop([0,1])\n",
    "for i in range(3):\n",
    "    # Use `hole` to create a donut-like pie chart\n",
    "    fig = go.Figure(data=[go.Pie(labels=df['index'], values=df[i+38], hole=.4, marker_colors=['#F5D042', '#0A174E', '#09663D'])])\n",
    "    fig.update_layout(legend=dict(xanchor=\"left\",x=0.65), title='향후 거주 의사',font=dict(size=18))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 지수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 클러스터링 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pydeck 용 coordinates 만들어주기\n",
    "def multipolygon_to_coordinates(x):\n",
    "    lon, lat = x[0].exterior.xy\n",
    "    return [[x, y] for x, y in zip(lon, lat)]\n",
    "\n",
    "data32['coordinates'] = data32['geometry'].apply(multipolygon_to_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 시각화 함수\n",
    "def clustermap(df, X, Y):\n",
    "    layer1 = pdk.Layer('ScatterplotLayer', # 사용할 Layer 타입\n",
    "                  df, # 시각화에 쓰일 데이터프레임\n",
    "                  get_position=[X, Y], # geometry 정보를 담고있는 컬럼 이름\n",
    "                  get_color='색상', # 각 데이터 별 rgb 또는 rgba 값 (0~255) # 마지막이 투명도 (0~255사이)\n",
    "                  get_radius=100\n",
    "                  #wireframe=True, # 마우스 오버(hover) 시 박스 출력 \n",
    "                  ) # 3D의 경우 값의 높이를 val 변수를 통해 하겠다.\n",
    "\n",
    "    layer2 = pdk.Layer('PolygonLayer', \n",
    "                       data32, \n",
    "                       get_polygon='coordinates', \n",
    "                       get_fill_color='[100,150,200,30]',\n",
    "                       get_line_color='[255, 255, 255]',\n",
    "                       pickable=True, \n",
    "                       lineWidthScale=15,\n",
    "                       auto_highlight=True)\n",
    "\n",
    "    center = [127.261575, 36.562811]\n",
    "    view_state = pdk.ViewState(\n",
    "        longitude=center[0],\n",
    "        latitude=center[1],\n",
    "        zoom=9.7)\n",
    "\n",
    "    r = pdk.Deck(layers=[layer1,layer2], initial_view_state=view_state,\n",
    "                 mapbox_key ='pk.eyJ1Ijoia3Nra253IiwiYSI6ImNra2NyejlqNzAzamsyb3BtbndvMnVvZjYifQ.xGhIzKCQe1mfade6s__fNw', \n",
    "                 map_style='mapbox://styles/mapbox/dark-v9')\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상권 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HDBSCAN으로 상권 클러스터링\n",
    "clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.0022)\n",
    "df = data14\n",
    "clusterer.fit(df[['lon', 'lat']])\n",
    "df['cluster'] = clusterer.labels_\n",
    "print(len(df['cluster'].unique()))\n",
    "print(len(df[df['cluster'] == -1]))\n",
    "df = df[df['cluster'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "색상 = []\n",
    "for kind in df['cluster']:\n",
    "    np.random.seed(kind + 10000)\n",
    "    \n",
    "    색상_temp = np.random.randint(250, size=(3, )).tolist()\n",
    "    if kind == -1:\n",
    "        색상_temp.extend([0])\n",
    "    else:\n",
    "        색상_temp.extend([170])\n",
    "    \n",
    "    색상.append(색상_temp)\n",
    "    \n",
    "df['색상'] = 색상\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustermap(df, 'lon','lat').to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop = df.groupby('cluster').count()['lon'][df.groupby('cluster').count()['lon'] <= 25].index\n",
    "clustermap(df[~df['cluster'].isin(drop)], 'lon','lat').to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('제거 전: ', len(df['cluster'].unique()))\n",
    "print('제거 후: ', len(df[~df['cluster'].isin(drop)]['cluster'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "store_delete = df[~df['cluster'].isin(drop)]\n",
    "store_delete = gpd.GeoDataFrame(store_delete, geometry= gpd.points_from_xy(store_delete.lon, store_delete.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#같은 군집에 속하는 좌표들의 합집합을 구하고, 그 합집합의 중점 구하기\n",
    "aca_cluster = {\"cluster\":[],\"lon\":[], \"lat\":[]}\n",
    "\n",
    "for i in list(store_delete.cluster.unique()):\n",
    "    aca_cluster[\"cluster\"].append(i)\n",
    "    aca_cluster[\"lon\"].append(store_delete[store_delete.cluster == i].unary_union.centroid.x)\n",
    "    aca_cluster[\"lat\"].append(store_delete[store_delete.cluster == i].unary_union.centroid.y)\n",
    "    \n",
    "store_cluster_df = pd.DataFrame(aca_cluster)\n",
    "store_cluster_geo = gpd.GeoDataFrame(store_cluster_df, geometry = gpd.points_from_xy(store_cluster_df.lon,store_cluster_df.lat))\n",
    "store_cluster_geo.crs = geo.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학원가 클러스터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HDBSCAN으로 학원가 클러스터링\n",
    "clusterer = hdbscan.HDBSCAN(cluster_selection_epsilon=0.003)\n",
    "df = academy \n",
    "clusterer.fit(df[['X', 'Y']])\n",
    "df['cluster'] = clusterer.labels_\n",
    "print(len(df['cluster'].unique()))\n",
    "print(len(df[df['cluster'] == -1]))\n",
    "df = df[df['cluster'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "색상 = []\n",
    "for kind in df['cluster']:\n",
    "    np.random.seed(kind + 10000)\n",
    "    \n",
    "    색상_temp = np.random.randint(250, size=(3, )).tolist()\n",
    "    if kind == -1:\n",
    "        색상_temp.extend([0])\n",
    "    else:\n",
    "        색상_temp.extend([170])\n",
    "    \n",
    "    색상.append(색상_temp)\n",
    "    \n",
    "df['색상'] = 색상\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustermap(df, 'X','Y').to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop = df.groupby('cluster').count()['X'][df.groupby('cluster').count()['X'] <= 20].index\n",
    "clustermap(df[~df['cluster'].isin(drop)], 'X','Y').to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('제거 전: ', len(df['cluster'].unique()))\n",
    "print('제거 후: ', len(df[~df['cluster'].isin(drop)]['cluster'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "academy_delete = df[~df['cluster'].isin(drop)]\n",
    "academy_delete = gpd.GeoDataFrame(academy_delete, geometry= gpd.points_from_xy(academy_delete.X, academy_delete.Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#같은 군집에 속하는 좌표들의 합집합을 구하고, 그 합집합의 중점 구하기\n",
    "aca_cluster = {\"cluster\":[],\"lon\":[], \"lat\":[]}\n",
    "\n",
    "for i in list(academy_delete.cluster.unique()):\n",
    "    aca_cluster[\"cluster\"].append(i)\n",
    "    aca_cluster[\"lon\"].append(academy_delete[academy_delete.cluster == i].unary_union.centroid.x)\n",
    "    aca_cluster[\"lat\"].append(academy_delete[academy_delete.cluster == i].unary_union.centroid.y)\n",
    "    \n",
    "academy_cluster_df = pd.DataFrame(aca_cluster)\n",
    "academy_cluster_geo = gpd.GeoDataFrame(academy_cluster_df, geometry = gpd.points_from_xy(academy_cluster_df.lon,academy_cluster_df.lat))\n",
    "academy_cluster_geo.crs = geo.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 지수 생성용 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 별 개수 구해서 추가하는 함수 정의\n",
    "def grid_count(df, name):\n",
    "    df = df.groupby('id').count().reset_index()\n",
    "    df = df[['id','SIG_KOR_NM']]\n",
    "    df.columns = ['id', name]\n",
    "    return df\n",
    "\n",
    "# 그리드 별 평균 구해서 추가하는 함수 정의\n",
    "def grid_mean(df, name):\n",
    "    df = df.groupby('id').mean().reset_index()\n",
    "    df = df[['id','SIG_KOR_NM']]\n",
    "    df.columns = ['id', name]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 안전 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 별 가로등 개수 구하기\n",
    "df_light = grid_count(street_lights, '가로등')\n",
    "\n",
    "# 그리드 별 파출소 개수 구하기\n",
    "df_police_office = grid_count(police_office, '파출소')\n",
    "\n",
    "# 그리드 별 cctv 개수 구하기\n",
    "df_cctv = cctv.groupby('id').sum().reset_index()[['id','카메라대수']]\n",
    "df_cctv['카메라대수'] = df_cctv['카메라대수']*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dfs = [geo, df_light, df_police_office, df_cctv]\n",
    "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
    "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)\n",
    "safety = df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통 지수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역, 터미널과의 거리의 경우에는,  \n",
    "- 오송역  \n",
    "- 반석역  \n",
    "- 조치원역  \n",
    "- 세종고속시외버스터미널  \n",
    "- 조치원공영버스터미널   \n",
    "을 고려함\n",
    "\n",
    "제외한 역  \n",
    "- 전의역, 부강역도 하루에 몇 번 정차하지만 이용하기 불편한 횟수  \n",
    "- 전동역, 서창역, 내판역, 매포역, 소정리역은 모든 여객열차가 정차하지 않음  \n",
    "- 청주역: 충북이기도 하고, 사람들이 엄청 다니는 역도 아님.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 별 버스 별 배차 개수 구하기\n",
    "df_bus = bus[['id','BRT','광역버스','지선버스','간선버스','마을버스']]\n",
    "df_bus=df_bus.groupby([\"id\"])['BRT','광역버스','지선버스','간선버스','마을버스'].sum().reset_index()\n",
    "\n",
    "#  그리드 별 중앙 좌표와 가까운 역, 터미널과의 거리 구하기\n",
    "station = pd.read_csv('sejong_stations.csv')\n",
    "station_geo= gpd.GeoDataFrame(station, geometry = gpd.points_from_xy(station.경도, station.위도))\n",
    "station_geo.crs = geo.crs\n",
    "\n",
    "distance_station = []\n",
    "\n",
    "for i in geo['geometry']:\n",
    "    temp = []\n",
    "    for j in station_geo['geometry']:\n",
    "        temp.append(i.distance(j))\n",
    "    \n",
    "    distance_station.append(min(temp)) \n",
    "    \n",
    "station_dist = geo.copy()\n",
    "station_dist[\"역 터미널\"] = distance_station\n",
    "station_dist = station_dist[['id', '역 터미널']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dfs = [geo, df_bus, station_dist]\n",
    "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
    "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 거리가 멀수록 페널티를 주기 위해 Hyperbolic Tangent 도함수에 넣어준 뒤, 정규화를 진행합니다\n",
    "def diff_tanh(x):\n",
    "    return 4/(np.exp(2*x)+2+np.exp(-2*x))\n",
    "\n",
    "dfdf = diff_tanh(df_merge['역 터미널'])\n",
    "\n",
    "dfdf = pd.DataFrame(dfdf, columns=['역 터미널'])\n",
    "df_merge['역 터미널']=dfdf['역 터미널']\n",
    "transport=df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생활 편의 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 그리드 별 병원 개수 구하기\n",
    "df_hospital = grid_count(hospital, '병원')\n",
    "\n",
    "# 그리드 별 은행 개수 구하기\n",
    "df_banks = grid_count(banks, '은행')\n",
    "\n",
    "# 그리드 별 학교 개수 구하기\n",
    "df_schools = school.groupby(['id','학교구분']).count().unstack()\n",
    "df_schools = df_schools[df_schools.columns[0:3]].reset_index()\n",
    "df_schools.columns = ['id','고등학교', '중학교', '초등학교']\n",
    "\n",
    "# 그리드 별 공원 개수 구하기\n",
    "df_parks = grid_count(parks, '공원')\n",
    "\n",
    "# 그리드 별 학원 개수 구하기\n",
    "df_academy = grid_count(academy, '학원')\n",
    "\n",
    "# 그리드 별 편의점 개수 구하기\n",
    "df_stores = grid_count(stores, '편의점')\n",
    "\n",
    "# 그리드 별 마트 개수 구하기\n",
    "df_mart = grid_count(mart, '마트')\n",
    "\n",
    "# 그리드 별 약국 개수 구하기\n",
    "df_pharmacy = grid_count(pharmacy, '약국')\n",
    "\n",
    "# 그리드 별 중앙 좌표와 가까운 상권과의 거리 구하기\n",
    "distance_store = []\n",
    "for i in geo['geometry']:\n",
    "    temp = []\n",
    "    for j in store_cluster_geo['geometry']:\n",
    "        temp.append(i.distance(j))\n",
    "    \n",
    "    distance_store.append(min(temp))\n",
    "store_dist = geo.copy()\n",
    "store_dist[\"상권\"] = distance_store\n",
    "store_dist = store_dist[['id', '상권']]\n",
    "\n",
    "\n",
    "# 그리드 별 중앙 좌표와 가까운 학원가와의 거리 구하기\n",
    "distance_academy = []\n",
    "for i in geo['geometry']:\n",
    "    temp = []\n",
    "    for j in academy_cluster_geo['geometry']:\n",
    "        temp.append(i.distance(j))\n",
    "    \n",
    "    distance_academy.append(min(temp)) \n",
    "academy_dist = geo.copy()\n",
    "academy_dist[\"학원가\"] = distance_academy\n",
    "academy_dist = academy_dist[['id', '학원가']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dfs = [geo, df_hospital, df_banks, df_schools, df_parks, df_academy, \n",
    "       df_stores, df_pharmacy, df_mart, store_dist, academy_dist]\n",
    "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs)\n",
    "df_merge = df_merge.drop(['left','top','right','bottom','SIG_CD','SIG_KOR_NM'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 거리가 멀수록 페널티를 주기 위해 Hyperbolic Tangent 도함수에 넣어준 뒤, 정규화를 진행합니다\n",
    "def diff_tanh(x):\n",
    "    return 4/(np.exp(2*x)+2+np.exp(-2*x))\n",
    "\n",
    "dfdf = diff_tanh(df_merge[['상권','학원가']])\n",
    "df_merge[['상권','학원가']]=dfdf[['상권','학원가']]\n",
    "life = df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 여러 변수 간 존재하는 상관관계를 이용, 이를 대표하는 주성분을 추출하여 차원 축소하는 방법\n",
    "\n",
    "- 각각 요소의 특징을 가장 잘 대변하는 단일 종합 지수 생성을 위해 PCA 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생활지수 \n",
    "\n",
    "- 은행, 초등학교, 중학교, 고등학교, 공원, 학원, 편의점, 약국, 마트, 병원, 그리드별 가까운 상권/학원가와의 직선거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NA 값은 0개이기에, 0으로 입력해준다.\n",
    "life['은행']=life['은행'].fillna(0)\n",
    "life['고등학교']=life['고등학교'].fillna(0)\n",
    "life['중학교']=life['중학교'].fillna(0)\n",
    "life['초등학교']=life['초등학교'].fillna(0) \n",
    "life['공원']=life['공원'].fillna(0)\n",
    "life['학원']=life['학원'].fillna(0)\n",
    "life['편의점']=life['편의점'].fillna(0) \n",
    "life['약국']=life['약국'].fillna(0)\n",
    "life['마트']=life['마트'].fillna(0)\n",
    "life['병원']=life['병원'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
    "id=life['id']\n",
    "\n",
    "# PCA를 위해 x 설정.\n",
    "x=life[['은행','고등학교','중학교','초등학교','공원','학원','편의점','약국','마트','상권','학원가']]\n",
    "\n",
    "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
    "\n",
    "pca= PCA(n_components = 1)\n",
    "PC=pca.fit_transform(x)\n",
    "result1 = pd.DataFrame(PC, columns=['PC1'])\n",
    "result1['id']=id # pca결과에 id 데이터 추가.\n",
    "\n",
    "# PCA PC1값에 minmax scaling을 해주었다. \n",
    "# 이유: 다중회귀분석 \n",
    "min_max_scaler = MinMaxScaler(feature_range=(5,100))\n",
    "x=result1['PC1']\n",
    "x=x.to_numpy(dtype=float)\n",
    "x=x.reshape(-1,1)\n",
    "x1= min_max_scaler.fit_transform(x)\n",
    "result1 = pd.DataFrame(x1, columns=['PC1'])\n",
    "result1['id']=id # pca결과에 id 데이터 추가.\n",
    "life_rate = result1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 안전지수\n",
    "\n",
    "- 가로등, 파출소, CCTV 대수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NA 값은 0개이기에, 0으로 채워준다.\n",
    "safety['가로등']=safety['가로등'].fillna(0)\n",
    "safety['파출소']=safety['파출소'].fillna(0)\n",
    "safety['카메라대수']=safety['카메라대수'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
    "id=safety['id']\n",
    "x=safety[['가로등','파출소','카메라대수']]\n",
    "\n",
    "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
    "pca= PCA(n_components = 1)\n",
    "PC=pca.fit_transform(x)\n",
    "result2 = pd.DataFrame(PC, columns=['PC1'])\n",
    "result2['id']=id\n",
    "\n",
    "# PCA PC1값에 minmax scaling을 해주었다. \n",
    "# 이유: 다중회귀분석 \n",
    "x=result2['PC1']\n",
    "x=x.to_numpy(dtype=float)\n",
    "x=x.reshape(-1,1)\n",
    "x1= min_max_scaler.fit_transform(x)\n",
    "result2 = pd.DataFrame(x1, columns=['PC1'])\n",
    "result2['id']=id \n",
    "safety_rate = result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통지수\n",
    "\n",
    "- BRT, 광역, 지선, 간선, 마을버스 기준 그리드별 배차 횟수, 그리드별 중앙 좌표와 가까운 역, 터미널과의 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transport['BRT']=transport['BRT'].fillna(0) # NA값 0으로 대체\n",
    "transport['광역버스']=transport['광역버스'].fillna(0)\n",
    "transport['지선버스']=transport['지선버스'].fillna(0)\n",
    "transport['간선버스']=transport['간선버스'].fillna(0)\n",
    "transport['마을버스']=transport['마을버스'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 후, plot_grid_map을 하기 위해 ID가 필요하므로 미리 추출한다.\n",
    "id=transport['id']\n",
    "x=transport[['BRT','광역버스','지선버스','간선버스','마을버스','역 터미널']]\n",
    "\n",
    "# PCA를 활용하여 지수를 만드는 것이기에, n_components 1로 고정.\n",
    "pca= PCA(n_components = 1)\n",
    "PC=pca.fit_transform(x)\n",
    "result3 = pd.DataFrame(PC, columns=['PC1'])\n",
    "result3['id']=id\n",
    "\n",
    "# PCA PC1값에 minmax scaling을 해주었다. \n",
    "# 이유: 다중회귀분석 \n",
    "min_max_scaler = MinMaxScaler(feature_range=(5,100))\n",
    "x=result3['PC1']\n",
    "x=x.to_numpy(dtype=float)\n",
    "x=x.reshape(-1,1)\n",
    "x1= min_max_scaler.fit_transform(x)\n",
    "result3 = pd.DataFrame(x1, columns=['PC1'])\n",
    "result3['id']=id \n",
    "transport_rate = result3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 생활 편의 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
    "pca = pd.merge(life_rate,geo,on='id',how='outer')\n",
    "pca = gpd.GeoDataFrame(pca)\n",
    "\n",
    "plot_grid_map(pca, col = 'PC1', title = '생활 편의 지수', k=12,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Purples', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 안전 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
    "pca = pd.merge(safety_rate,geo,on='id',how='outer')\n",
    "pca = gpd.GeoDataFrame(pca)\n",
    "\n",
    "plot_grid_map(pca, col = 'PC1', title = '안전 지수', k=12,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Greens', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교통 지수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PCA 결과를 바탕으로 geo(격자) 데이터와 합쳐준다.\n",
    "pca = pd.merge(transport_rate,geo,on='id',how='outer')\n",
    "pca = gpd.GeoDataFrame(pca)\n",
    "\n",
    "plot_grid_map(pca, col = 'PC1', title = '교통 지수', k=12,\n",
    "              mode = 'cont_classify',c_mode = 'FisherJenks', colors = 'Blues', percen = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) LDA\n",
    "\n",
    "- NLP 토픽 모델링의 대표적인 알고리즘\n",
    "\n",
    "- 문서의 집합들을 바탕으로 하며, 단어가 특정 토픽에 존재할 확률과 문서에 특정 토픽이 존재할 확률을 결합확률로 추정하여 문서 내에 어떤 토픽들이 존재하는지 알아내는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ldamodel(df, n=4):\n",
    "    # 토큰 추출\n",
    "    token = df['token']\n",
    "    dictionary = corpora.Dictionary(token)\n",
    "    corpus = [dictionary.doc2bow(text) for text in token]\n",
    "    \n",
    "    #LDA 모델 훈련시키기\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = n, id2word=dictionary, passes=15)\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017년 4월 1일 ~ 6월 30일\n",
    "\n",
    "- 대선 주자들의 세종시 관련 공약들로 인해 세종시 주택시장에 대한 관심이 증폭되던 시기\n",
    "\n",
    "- 세종시 주택 매매량이 증가하고 아파트 거래가 상승 폭을 보인 시기\n",
    "\n",
    "- 아파트 거래와 동시에 인구의 유입도 많았던 시기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.display(ldamodel(df_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2017년 7월 1일 ~ 10월 31일\n",
    "\n",
    "- 문재인 정권의 8.2 부동산 정책이 시행되었던 시기  \n",
    "- 세종시 주택 매매 거래량이 감소하고 특히 아파트 거래가 하락 폭을 보인 시기  \n",
    "- 인구의 유입도 점차 줄어들던 시기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.display(ldamodel(df_3, n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2019년 10월 1일 ~ 12월 31일\n",
    "- 전국의 주택 시장이 상승장의 모습을 띄었던 시기  \n",
    "- 세종시 주택 거래 중 매매거래가 폭등하고, 전월세 거래 또한 상승세의 시기  \n",
    "- 폭발적으로 늘어난 주택 거래량과는 달리 순유입자수 증가율은 오히려 감세를 보였다는 점이 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.display(ldamodel(df_8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2020년 5월 1일 ~ 7월 31일\n",
    "- 전국의 주택 시장이 상승장의 모습을 띄었던 시기  \n",
    "- 세종시 주택 거래 중 매매거래가 폭등하고, 전월세 거래 또한 상승세의 시기\n",
    "- 폭발적으로 늘어난 주택 거래량과는 달리 순유입자수 증가율은 오히려 감세를 보였다는 점이 특징"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.display(ldamodel(df_10, n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Multiple Regression Analysis\n",
    "\n",
    "- 두 개 이상의 연속형 독립변수가 연속형 종속변수에는 미치는 영향을 검증하는 분석 방법\n",
    "\n",
    "- 독립변수 분석: 종속변수와 관련이 있는 주요 독립변수 파악"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 격자 Data  전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 격자데이터 읍면동별로 분류\n",
    "df = gpd.sjoin(geo, data32, op='intersects', how='left')\n",
    "dff = df.groupby('id').count().reset_index()\n",
    "fine = dff[dff['left'] == 1][['id','left']]#하나씩으로 정상적으로 나눠진 데이터\n",
    "fine = pd.merge(fine, df, on='id')[['id','ADM_DR_NM','left_x']]\n",
    "dff = dff[dff['left']>1][['id','left']] #두개 이상이 할당된 데이터\n",
    "df2 = pd.merge(dff, df, on='id')[['id','ADM_DR_NM','left_x']]\n",
    "\n",
    "# 조치원 부분만 처리\n",
    "eup = df2[df2['ADM_DR_NM'].str[3] == '읍']\n",
    "a = eup['id'].unique().tolist()\n",
    "eup = df2[df2['id'].isin(a)]\n",
    "df2 = df2.drop(eup.index)\n",
    "eup = eup[eup['ADM_DR_NM'].str[3] == '읍']\n",
    "\n",
    "\n",
    "# 중복되는 읍면동 drop\n",
    "dropdu = df2[['id','left_x']].drop_duplicates().index\n",
    "df2 = df2.loc[dropdu,:]\n",
    "done = pd.concat([fine, df2, eup])\n",
    "emdgeo = pd.merge(done,geo, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 읍면동 지역으로 나누어서 그리드 확인\n",
    "eup = emdgeo[emdgeo['ADM_DR_NM'].str[3] == '읍']\n",
    "myun = emdgeo[emdgeo['ADM_DR_NM'].str[2] == '면']\n",
    "dong = emdgeo[emdgeo['ADM_DR_NM'].str[2] == '동']\n",
    "\n",
    "print('읍: ', len(eup))\n",
    "print('면: ', len(myun))\n",
    "print('동: ', len(dong))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 지역구분 column 추가\n",
    "eup['지역 구분'] = '읍'\n",
    "myun['지역 구분'] = '면'\n",
    "dong['지역 구분'] = '동'\n",
    "df = pd.concat([eup, myun, dong])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 지수(생활 편의, 안전, 교통), 공시지가, 인구 데이터 Column으로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "life_rate.columns = ['life','id']\n",
    "safety_rate.columns = ['safety','id']\n",
    "transport_rate.columns = ['transport','id']\n",
    "gs = gongsi2[['id',2020,'변동률']]\n",
    "gs.columns = ['id','공시지가','공시지가 변동률']\n",
    "pop2020 = pop2020[['id','총합']].fillna(0).replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "popin = popin[['index',0]].fillna(0)\n",
    "popin.columns = ['ADM_DR_NM','순전입자수']\n",
    "# 순전입자수가 너무 많기 때문에 scaling 진행\n",
    "min_max_scaler = MinMaxScaler(feature_range=(5,100))\n",
    "x=popin['순전입자수']\n",
    "x=x.to_numpy(dtype=float)\n",
    "x=x.reshape(-1,1)\n",
    "x1= min_max_scaler.fit_transform(x)\n",
    "popin['순전입자수'] = x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age = age.replace(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "dfs = [df,life_rate,safety_rate,transport_rate, gs, age, pop2020]\n",
    "df_merge = reduce(lambda left, right: pd.merge(left, right, on='id', how='outer'), dfs, )\n",
    "df_merge = pd.merge(df_merge, popin, on='ADM_DR_NM')\n",
    "emd = df_merge.drop(['left_x','left','top','bottom','SIG_CD','SIG_KOR_NM'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eup = emd[emd['지역 구분'] == '읍']\n",
    "myun = emd[emd['지역 구분'] == '면']\n",
    "dong = emd[emd['지역 구분'] == '동']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중선형회귀( Level-log Model) 함수 정의\n",
    "\n",
    "- x가 1%만큼 증가할 때 y가 $\\frac{\\beta}{100}$% 만큼 변하는 것을 의미하는 분석 방법 ➡︎ 독립변수를 단위화  \n",
    "  \n",
    "- 독립변수가 단위에 영향을 받지 않도록 행복지수, 안전지수, 교통지수에 대해서 Level-log Model을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "def log(df):\n",
    "    # 공시지가 na 값 drop 후, na 아닌 데이터만 추출\n",
    "    df=df.reset_index()\n",
    "    df1=df['공시지가'].dropna()\n",
    "    index=df1.index\n",
    "    df=df.loc[index]\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    # 로그 씌워주기\n",
    "    df['log생활지수']=np.log(df['life'])\n",
    "    df['log안전지수']=np.log(df['safety'])\n",
    "    df['log교통지수']=np.log(df['transport'])\n",
    "    df['log건축연한']=np.log(df['사용연도'])\n",
    "    df['건축연한']=df['사용연도']\n",
    "    df['log순전입자수']=np.log(df['순전입자수'])\n",
    "\n",
    "    return df\n",
    "\n",
    "def ourols(df, log=False):\n",
    "    # 회귀 돌려주기\n",
    "    res = ols('공시지가 ~ log생활지수+log안전지수+log교통지수+순전입자수', data=df).fit()\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 읍 (log-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res1 = ourols(log(eup))\n",
    "res1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 면 (log-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res2 = ourols(log(myun))\n",
    "res2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 동 (log-level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res3 = ourols(log(dong))\n",
    "res3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Oaxaca-Blinder Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형회귀계수를 이용해 격차를 세 가지 부분으로 분해해 격차의 발생요인을 설명하는 분석 방법\n",
    "\n",
    "- 가격 격차가 어디서 기인하는지 분석하기 위해 Oaxaca-Blinder 분해법 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 읍 X와 y값 지정.\n",
    "X_eup=log(eup)[['log생활지수','log안전지수','log교통지수','순전입자수']]\n",
    "y_eup=log(eup)['공시지가']\n",
    "\n",
    "# 면 X와 y값 지정.\n",
    "X_myun=log(myun)[['log생활지수','log안전지수','log교통지수','순전입자수']]\n",
    "y_myun=log(myun)['공시지가']\n",
    "\n",
    "# 동 X와 y값 지정.\n",
    "X_dong=log(dong)[['log생활지수','log안전지수','log교통지수','순전입자수']]\n",
    "y_dong=log(dong)['공시지가']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 읍, 면 vs 동 Beta(coefficient)계수 벡터화\n",
    "b_eup = np.asarray(res1.params[1:])\n",
    "b_myun = np.asarray(res2.params[1:])\n",
    "b_dong = np.asarray(res3.params[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 읍, 면 vs 동 독립변수 mean 벡터화\n",
    "x_eup = np.asarray(X_eup.mean())\n",
    "x_myun = np.asarray(X_myun.mean())\n",
    "x_dong = np.asarray(X_dong.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('읍 공시지가 평균: ',y_eup.mean())\n",
    "print('면 공시지가 평균: ',y_myun.mean())\n",
    "print('동 공시지가 평균: ',y_dong.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Endowments: 설명 변수 차이로 인해 발생하는 격차\n",
    "\n",
    "- Coefficients: 각 그룹의 회귀 계수 차이로 인해 발생하는 격차\n",
    "\n",
    "- Interaction: 모델로 설명할 수 없는 부분 (잔차)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def oaxaca(x1, x2, b1, b2):\n",
    "    \n",
    "    X=x1-x2\n",
    "    B=b1-b2\n",
    "    \n",
    "    endowments=[]\n",
    "    coefficients=[]\n",
    "    interaction=[]\n",
    "    \n",
    "    for i in range(4):\n",
    "        endowments.append(X[i]*b2[i])\n",
    "        coefficients.append(x2[i]*B[i])\n",
    "        interaction.append(X[i]*B[i])\n",
    "    df = DataFrame()\n",
    "    df['endowments'] = endowments\n",
    "    df['coefficents'] = coefficients\n",
    "    df['interaction'] = interaction\n",
    "    df['variable'] = ['loglife','logsafety','logtransport','순전입자수']\n",
    "    df = df.set_index('variable')\n",
    "    df2 = DataFrame(df.transpose())\n",
    "    df2['sum'] = df.sum()\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oaxaca(x_dong, x_myun, b_dong, b_myun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oaxaca(x_dong, x_eup, b_dong, b_eup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
